import os
import logging
from llm_api import call_llm_openrouter
import re # Added for advanced_intent_reconstruction
from purpose_based_template_system import get_purpose_based_template_system

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def classify_intent(user_input: str) -> str:
    """
    ì‚¬ìš©ì ì…ë ¥ì„ ê¸°ë°˜ìœ¼ë¡œ ì˜ë„ë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤.
    
    Args:
        user_input (str): ë¶„ë¥˜í•  ì‚¬ìš©ì ì…ë ¥
        
    Returns:
        str: ë¶„ë¥˜ëœ ì˜ë„ (business_plan, collaboration_email, customer_reply, summary, complaint, self_intro, etc)
    """
    prompt = f"""
ë‹¤ìŒ ë¬¸ì¥ì€ ì–´ë–¤ ëª©ì ì˜ ë¬¸ì¥ì¸ê°€ìš”? ì•„ë˜ ì¤‘ í•˜ë‚˜ë¡œ ë¶„ë¥˜í•´ì£¼ì„¸ìš”:
- business_plan
- collaboration_email
- customer_reply
- summary
- complaint
- self_intro
- etc

ë¬¸ì¥: "{user_input}"
"""
    try:
        response = call_llm_openrouter(prompt)
        response = response.lower().strip()
        
        # ìœ íš¨í•œ ì˜ë„ ëª©ë¡
        valid_intents = [
            "business_plan", "collaboration_email", "customer_reply", 
            "summary", "complaint", "self_intro", "etc"
        ]
        
        # ì‘ë‹µì—ì„œ ìœ íš¨í•œ ì˜ë„ ì°¾ê¸°
        for intent in valid_intents:
            if intent in response:
                return intent
        
        # ì‘ë‹µì—ì„œ ì˜ë„ê°€ ëª…í™•í•˜ì§€ ì•Šì€ ê²½ìš° "etc" ë°˜í™˜
        return "etc"
        
    except Exception as e:
        logger.error(f"ì˜ë„ ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
        return "etc"

def extract_intent_and_purpose(user_input: str, chat_history: list = None) -> dict:
    """
    ğŸ¯ [ğŸ“Œ REFINED CURSOR INSTRUCTION: Enhanced Context-Aware Intent Classification]
    
    If the user's intent is **not clearly classifiable**, refer to prior messages (chat history) 
    to infer their likely goal. Reclassify the intent based on inferred purpose 
    (e.g., if "Make an IR draft" is detected, override 'general_inquiry' with 'investor_IR_document').
    
    Use the inferred intent to select or construct the appropriate system prompt template.
    Avoid generic fallback templates unless absolutely necessary.
    Always match prompt tone, style, and structure to the purpose 
    (e.g., professional for investors, casual for friend advice).
    
    Args:
        user_input (str): The user's utterance
        chat_history (list): Optional chat history for context
        
    Returns:
        dict: Contains intent, purpose, and system prompt
    """
    user_input_lower = user_input.lower()
    
    # Check if input is ambiguous or informal
    ambiguous_patterns = [
        "ê·¸ëƒ¥", "ì‚¬ëŒ", "ê°ì„±", "ìê·¹", "ì¨ì¤˜", "ì´ê±°", "ìš”ì¦˜", "ëŒ€ì„¸", "ê´œì°®ì•„", "ëŒ€ë°•", 
        "ë‚˜ë„ í• ê¹Œ", "í˜•", "bro", "this", "trend", "cool", "awesome", "should i", 
        "is this ok", "wow", "just", "people", "emotion", "stimulate", "write"
    ]
    
    is_ambiguous_or_informal = any(pattern in user_input_lower for pattern in ambiguous_patterns)
    
    # Enhanced intent classification with context awareness and reclassification
    intent_mapping = {
        "marketing_copy": {
            "keywords": ["ë§ˆì¼€íŒ…", "ê´‘ê³ ", "í™ë³´", "ë¸Œëœë”©", "marketing", "advertising", "promotion", "branding"],
            "context_keywords": ["ê°ì„±", "ìê·¹", "ì‚¬ëŒ", "ê³ ê°", "emotion", "stimulate", "people", "customer"],
            "korean_classification": "ë§ˆì¼€íŒ… ì¹´í”¼ ì‘ì„± ìš”ì²­",
            "description": "ê°ì„±ì ì´ê³  ì„¤ë“ë ¥ ìˆëŠ” ë§ˆì¼€íŒ… ì¹´í”¼ ì‘ì„± ìš”ì²­",
            "tone": "persuasive",
            "style": "emotional",
            "audience": "customer"
        },
        "content_creation": {
            "keywords": ["ì½˜í…ì¸ ", "ê¸€", "ì‘ì„±", "content", "writing", "article", "post"],
            "context_keywords": ["ê·¸ëƒ¥", "ì¨ì¤˜", "just", "write"],
            "korean_classification": "ì½˜í…ì¸  ì‘ì„± ìš”ì²­",
            "description": "ì¼ë°˜ì ì¸ ì½˜í…ì¸ ë‚˜ ê¸€ ì‘ì„± ìš”ì²­",
            "tone": "informative",
            "style": "engaging",
            "audience": "general"
        },
        "decision_making": {
            "keywords": ["í• ê¹Œ", "í•´ì•¼ í• ê¹Œ", "ì–´ë–»ê²Œ", "ì‹œë„", "í•´ë³¼ê¹Œ", "should i", "how", "try", "do it"],
            "context_keywords": ["íŒë‹¨", "ê²°ì •", "judgment", "decision"],
            "korean_classification": "í–‰ë™ ì—¬ë¶€ íŒë‹¨ ìš”ì²­",
            "description": "ì–´ë–¤ í–‰ë™ì„ ë”°ë¼ í• ì§€ì— ëŒ€í•œ íŒë‹¨ ìš”ì²­",
            "tone": "analytical",
            "style": "balanced",
            "audience": "personal"
        },
        "feasibility_judgment": {
            "keywords": ["ê°€ëŠ¥í• ê¹Œ", "ì‹¤í˜„ ê°€ëŠ¥", "feasible", "possible", "realistic"],
            "context_keywords": ["ê°€ëŠ¥ì„±", "ì‹¤í˜„", "possibility", "realization"],
            "korean_classification": "ì‹¤í˜„ ê°€ëŠ¥ì„± íŒë‹¨",
            "description": "íŠ¹ì • í–‰ë™ì´ë‚˜ ê³„íšì˜ ì‹¤í˜„ ê°€ëŠ¥ì„±ì— ëŒ€í•œ íŒë‹¨ ìš”ì²­",
            "tone": "analytical",
            "style": "thorough",
            "audience": "expert"
        },
        "advice_seeking": {
            "keywords": ["ì¡°ì–¸", "ë„ì›€", "ê°€ì´ë“œ", "ì œì•ˆ", "advice", "help", "guide", "suggestion"],
            "context_keywords": ["ì–´ë–»ê²Œ", "ë°©ë²•", "how", "method"],
            "korean_classification": "ì¡°ì–¸ ìš”ì²­",
            "description": "íŠ¹ì • ìƒí™©ì— ëŒ€í•œ ì¡°ì–¸ì´ë‚˜ ê°€ì´ë“œ ìš”ì²­",
            "tone": "supportive",
            "style": "practical",
            "audience": "personal"
        },
        "comparison_request": {
            "keywords": ["ì¹œêµ¬", "ë‹¤ë¥¸", "ë¹„êµ", "vs", "versus", "friend", "other", "compare"],
            "context_keywords": ["ì°¨ì´", "ë¹„êµ", "difference", "comparison"],
            "korean_classification": "ë¹„êµ ë¶„ì„ ìš”ì²­",
            "description": "ì—¬ëŸ¬ ì˜µì…˜ ê°„ì˜ ë¹„êµ ë¶„ì„ ìš”ì²­",
            "tone": "objective",
            "style": "comparative",
            "audience": "general"
        },
        "validation_seeking": {
            "keywords": ["ë§ë‚˜", "ì˜¬ë°”ë¥¸", "í™•ì¸", "ê²€ì¦", "right", "correct", "confirm", "validate"],
            "context_keywords": ["ê²€í† ", "í‰ê°€", "review", "evaluation"],
            "korean_classification": "ê²€ì¦ ìš”ì²­",
            "description": "í˜„ì¬ ì ‘ê·¼ ë°©ì‹ì´ë‚˜ ê²°ì •ì˜ ì ì ˆì„± ê²€ì¦ ìš”ì²­",
            "tone": "thorough",
            "style": "evaluative",
            "audience": "expert"
        },
        "doubt_expression": {
            "keywords": ["ëª¨ë¥´ê² ì–´", "ë¶ˆí™•ì‹¤", "ì˜ì‹¬", "ê±±ì •", "don't know", "uncertain", "doubt", "worry"],
            "context_keywords": ["ë¶ˆì•ˆ", "ê±±ì •", "anxiety", "concern"],
            "korean_classification": "ë¶ˆí™•ì‹¤ì„± í‘œí˜„",
            "description": "í˜„ì¬ ìƒí™©ì´ë‚˜ ê²°ì •ì— ëŒ€í•œ ë¶ˆí™•ì‹¤ì„±ì´ë‚˜ ê±±ì • í‘œí˜„",
            "tone": "empathetic",
            "style": "reassuring",
            "audience": "personal"
        },
        "trend_verification": {
            "keywords": ["ëŒ€ì„¸", "ìš”ì¦˜", "íŠ¸ë Œë“œ", "trend", "popular", "hot", "viral"],
            "context_keywords": ["ì¸ê¸°", "ìœ í–‰", "popularity", "fashion"],
            "korean_classification": "íŠ¸ë Œë“œ ê²€ì¦ ìš”ì²­",
            "description": "í˜„ì¬ íŠ¸ë Œë“œë‚˜ ì¸ê¸° ìˆëŠ” ê²ƒì— ëŒ€í•œ ê²€ì¦ ìš”ì²­",
            "tone": "informative",
            "style": "current",
            "audience": "general"
        },
        "casual_opinion": {
            "keywords": ["ê´œì°®ì•„", "ëŒ€ë°•", "ì¢‹ì•„", "cool", "awesome", "great", "nice"],
            "context_keywords": ["ì˜ê²¬", "í‰ê°€", "opinion", "evaluation"],
            "korean_classification": "ìºì£¼ì–¼ ì˜ê²¬ ìš”ì²­",
            "description": "ìºì£¼ì–¼í•œ ì˜ê²¬ì´ë‚˜ í‰ê°€ ìš”ì²­",
            "tone": "casual",
            "style": "friendly",
            "audience": "personal"
        },
        "investor_IR_document": {
            "keywords": ["IR", "íˆ¬ìì", "íˆ¬ì", "investor", "investment", "ì´ˆì•ˆ", "draft"],
            "context_keywords": ["ìë£Œ", "ë¬¸ì„œ", "document", "material"],
            "korean_classification": "íˆ¬ìì ê´€ê³„ ë¬¸ì„œ ì‘ì„± ìš”ì²­",
            "description": "íˆ¬ììë¥¼ ìœ„í•œ IR ë¬¸ì„œ ì‘ì„± ìš”ì²­",
            "tone": "professional",
            "style": "formal",
            "audience": "investor"
        },
        "business_plan": {
            "keywords": ["ì‚¬ì—…ê³„íšì„œ", "ë¹„ì¦ˆë‹ˆìŠ¤", "ì°½ì—…", "business plan", "startup", "company"],
            "context_keywords": ["ê³„íš", "ì „ëµ", "plan", "strategy"],
            "korean_classification": "ì‚¬ì—…ê³„íšì„œ ì‘ì„± ìš”ì²­",
            "description": "ì‚¬ì—…ê³„íšì„œ ì‘ì„± ìš”ì²­",
            "tone": "professional",
            "style": "strategic",
            "audience": "investor"
        },
        "proposal": {
            "keywords": ["ì œì•ˆì„œ", "ì œì•ˆ", "proposal", "suggestion", "recommendation"],
            "context_keywords": ["ì•ˆ", "ë°©ì•ˆ", "proposal", "solution"],
            "korean_classification": "ì œì•ˆì„œ ì‘ì„± ìš”ì²­",
            "description": "ì œì•ˆì„œ ì‘ì„± ìš”ì²­",
            "tone": "persuasive",
            "style": "structured",
            "audience": "client"
        }
    }
    
    # Context-aware intent classification with reclassification logic
    detected_intent = "general_inquiry"
    detected_classification = "ì¼ë°˜ì ì¸ ë¬¸ì˜"
    detected_description = "ì¼ë°˜ì ì¸ ì •ë³´ë‚˜ ê°€ì´ë“œ ìš”ì²­"
    detected_tone = "genuine"
    detected_style = "informative"
    detected_audience = "general"
    
    if is_ambiguous_or_informal and chat_history:
        # Use enhanced context-aware classification with reclassification
        detected_intent, detected_classification, detected_description, detected_tone, detected_style, detected_audience = classify_intent_with_context_enhanced(
            user_input, chat_history, intent_mapping
        )
    else:
        # Use keyword-based classification for clear inputs
        for intent, config in intent_mapping.items():
            if any(keyword in user_input_lower for keyword in config["keywords"]):
                detected_intent = intent
                detected_classification = config["korean_classification"]
                detected_description = config["description"]
                detected_tone = config.get("tone", "genuine")
                detected_style = config.get("style", "informative")
                detected_audience = config.get("audience", "general")
                break
    
    # Construct context-aware system prompt with purpose-driven template selection
    if is_ambiguous_or_informal and chat_history:
        # Enhanced context-aware prompt for ambiguous/informal inputs
        system_prompt = f"""ì‚¬ìš©ìì˜ ë°œí™”ëŠ” '{user_input}'ì…ë‹ˆë‹¤.
ì´ ë°œí™”ëŠ” ëª¨í˜¸í•˜ê±°ë‚˜ ë¹„ê²©ì‹ì ì´ë¯€ë¡œ, ì´ì „ ëŒ€í™” ê¸°ë¡ì„ ë¶„ì„í•˜ì—¬ ì‹¤ì œ ì˜ë„ì™€ ì£¼ì œ ë§¥ë½ì„ ì¶”ë¡ í•˜ì‹­ì‹œì˜¤.

ì´ì „ ëŒ€í™” ë§¥ë½:
{format_chat_history(chat_history)}

ì¶”ë¡ ëœ ì˜ë„: {detected_classification}
ì„¤ëª…: {detected_description}
í†¤: {detected_tone}
ìŠ¤íƒ€ì¼: {detected_style}
ëŒ€ìƒ: {detected_audience}

ë¶„ì„ ì§€ì¹¨:
1. í‚¤ì›Œë“œ ë§¤ì¹­ì—ë§Œ ì˜ì¡´í•˜ì§€ ë§ê³  ëŒ€í™” ë§¥ë½ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„
2. ì‚¬ìš©ìì˜ ì‹¤ì œ ëª©ì ê³¼ ì£¼ì œë¥¼ ëŒ€í™” íë¦„ì—ì„œ ì¶”ë¡ 
3. ëª¨í˜¸í•œ í‘œí˜„ì„ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ìš”ì²­ìœ¼ë¡œ í•´ì„
4. ì´ì „ ëŒ€í™”ì—ì„œ ì–¸ê¸‰ëœ ì£¼ì œë‚˜ ëª©ì ê³¼ ì—°ê²°
5. ì¶”ë¡ ëœ ì˜ë„ì— ë§ëŠ” ì ì ˆí•œ í†¤ê³¼ ìŠ¤íƒ€ì¼ ì ìš©

ì¶œë ¥ ìš”êµ¬ì‚¬í•­:
- ë°˜ë“œì‹œ í•œê¸€ë¡œ ì‘ì„±
- ì¶”ë¡ ëœ ëª©ì ì— ë§ëŠ” êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ì‘ë‹µ êµ¬ì„±
- ì‚¬ìš©ìì˜ ì‹¤ì œ ì˜ë„ë¥¼ ë°˜ì˜í•œ ë§ì¶¤í˜• ê°€ì´ë“œ ì œê³µ
- ë§¥ë½ì— ë§ëŠ” ë‹¤ìŒ ë‹¨ê³„ë‚˜ êµ¬ì²´ì ì¸ ì œì•ˆ í¬í•¨
- {detected_tone} í†¤ê³¼ {detected_style} ìŠ¤íƒ€ì¼ë¡œ {detected_audience} ëŒ€ìƒì—ê²Œ ì í•©í•œ ì‘ë‹µ"""
    else:
        # Standard prompt for clear inputs
        system_prompt = f"""ì‚¬ìš©ìì˜ ë°œí™”ëŠ” "{user_input}"ì…ë‹ˆë‹¤.
ì´ ë°œí™”ëŠ” '{detected_classification}'ìœ¼ë¡œ ë¶„ë¥˜ë©ë‹ˆë‹¤.
ì´ì— ë”°ë¼ ë‹¤ìŒ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” í•œê¸€ ì‘ë‹µì„ ìƒì„±í•˜ì‹­ì‹œì˜¤:

- í•´ë‹¹ ìƒí™©ì— ëŒ€í•œ ì‹¤ì§ˆì ì´ê³  ìœ ìš©í•œ ì¡°ì–¸
- ê°€ëŠ¥í•œ ì¥ë‹¨ì  ë° ê³ ë ¤ ìš”ì†Œ
- ì‚¬ìš©ìì˜ ìƒí™©ì— ë§ëŠ” êµ¬ì²´ì ì¸ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ
- {detected_tone} í†¤ê³¼ {detected_style} ìŠ¤íƒ€ì¼ë¡œ {detected_audience} ëŒ€ìƒì—ê²Œ ì í•©í•œ ì‘ë‹µ

ëª¨ë“  ì¶œë ¥ì€ ë°˜ë“œì‹œ í•œê¸€ë¡œ ìƒì„±í•˜ì‹­ì‹œì˜¤."""
    
    return {
        "intent": detected_intent,
        "korean_classification": detected_classification,
        "description": detected_description,
        "system_prompt": system_prompt,
        "is_context_aware": is_ambiguous_or_informal and chat_history is not None,
        "tone": detected_tone,
        "style": detected_style,
        "audience": detected_audience
    }

def classify_intent_with_context(user_input: str, chat_history: list, intent_mapping: dict) -> tuple:
    """
    ëŒ€í™” ë§¥ë½ì„ ê¸°ë°˜ìœ¼ë¡œ ì˜ë„ë¥¼ ë¶„ë¥˜í•©ë‹ˆë‹¤.
    
    Args:
        user_input (str): ì‚¬ìš©ì ë°œí™”
        chat_history (list): ëŒ€í™” íˆìŠ¤í† ë¦¬
        intent_mapping (dict): ì˜ë„ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬
        
    Returns:
        tuple: (intent, classification, description)
    """
    user_input_lower = user_input.lower()
    
    # Combine current input with recent chat history for context analysis
    context_text = user_input_lower
    if chat_history:
        # Extract recent messages for context
        recent_messages = chat_history[-3:]  # Last 3 messages
        for message in recent_messages:
            if isinstance(message, dict):
                content = message.get('content', '').lower()
            else:
                content = str(message).lower()
            context_text += " " + content
    
    # Score each intent based on both keywords and context
    intent_scores = {}
    
    for intent, config in intent_mapping.items():
        score = 0
        
        # Direct keyword matching (higher weight)
        for keyword in config["keywords"]:
            if keyword in user_input_lower:
                score += 3
        
        # Context keyword matching (medium weight)
        for keyword in config.get("context_keywords", []):
            if keyword in context_text:
                score += 2
        
        # Context analysis for specific patterns
        if intent == "marketing_copy" and any(word in context_text for word in ["ê°ì„±", "ìê·¹", "ì‚¬ëŒ", "emotion", "stimulate", "people"]):
            score += 5  # High score for marketing context
        
        elif intent == "content_creation" and any(word in user_input_lower for word in ["ê·¸ëƒ¥", "ì¨ì¤˜", "just", "write"]):
            score += 4  # High score for writing requests
        
        elif intent == "trend_verification" and any(word in context_text for word in ["ëŒ€ì„¸", "íŠ¸ë Œë“œ", "trend", "popular"]):
            score += 3
        
        elif intent == "casual_opinion" and any(word in user_input_lower for word in ["ê´œì°®ì•„", "ëŒ€ë°•", "cool", "awesome"]):
            score += 3
        
        intent_scores[intent] = score
    
    # Find the highest scoring intent
    if intent_scores:
        best_intent = max(intent_scores, key=intent_scores.get)
        if intent_scores[best_intent] > 0:
            config = intent_mapping[best_intent]
            return best_intent, config["korean_classification"], config["description"]
    
    # Default fallback
    return "general_inquiry", "ì¼ë°˜ì ì¸ ë¬¸ì˜", "ì¼ë°˜ì ì¸ ì •ë³´ë‚˜ ê°€ì´ë“œ ìš”ì²­"

def classify_intent_with_context_enhanced(user_input: str, chat_history: list, intent_mapping: dict) -> tuple:
    """
    ğŸ¯ [ğŸ“Œ REFINED CURSOR INSTRUCTION] í–¥ìƒëœ ë§¥ë½ ê¸°ë°˜ ì˜ë„ ë¶„ë¥˜ ë° ì¬ë¶„ë¥˜
    
    If the user's intent is **not clearly classifiable**, refer to prior messages (chat history) 
    to infer their likely goal. Reclassify the intent based on inferred purpose.
    
    Args:
        user_input (str): ì‚¬ìš©ì ë°œí™”
        chat_history (list): ëŒ€í™” íˆìŠ¤í† ë¦¬
        intent_mapping (dict): ì˜ë„ ë§¤í•‘ ë”•ì…”ë„ˆë¦¬
        
    Returns:
        tuple: (intent, classification, description, tone, style, audience)
    """
    user_input_lower = user_input.lower()
    
    # Combine current input with recent chat history for context analysis
    context_text = user_input_lower
    if chat_history:
        # Extract recent messages for context (last 5 messages for better context)
        recent_messages = chat_history[-5:]
        for message in recent_messages:
            if isinstance(message, dict):
                content = message.get('content', '').lower()
            else:
                content = str(message).lower()
            context_text += " " + content
    
    # Enhanced scoring system with reclassification logic
    intent_scores = {}
    
    for intent, config in intent_mapping.items():
        score = 0
        
        # Direct keyword matching (higher weight)
        for keyword in config["keywords"]:
            if keyword in user_input_lower:
                score += 4  # Increased weight
        
        # Context keyword matching (medium weight)
        for keyword in config.get("context_keywords", []):
            if keyword in context_text:
                score += 3  # Increased weight
        
        # Enhanced context analysis for specific patterns with reclassification
        if intent == "investor_IR_document":
            # Check for IR-related context in chat history
            ir_indicators = ["IR", "íˆ¬ìì", "íˆ¬ì", "investor", "investment", "ì´ˆì•ˆ", "draft", "ìë£Œ", "ë¬¸ì„œ"]
            if any(indicator in context_text for indicator in ir_indicators):
                score += 8  # Very high score for IR context
            # Reclassify from general_inquiry to investor_IR_document
            if "ì´ˆì•ˆ" in user_input_lower or "draft" in user_input_lower:
                score += 6
        
        elif intent == "business_plan":
            # Check for business plan context
            business_indicators = ["ì‚¬ì—…ê³„íšì„œ", "ë¹„ì¦ˆë‹ˆìŠ¤", "ì°½ì—…", "business", "startup", "company", "ê³„íš", "ì „ëµ"]
            if any(indicator in context_text for indicator in business_indicators):
                score += 7
            # Reclassify from general_inquiry to business_plan
            if "ê³„íšì„œ" in user_input_lower or "plan" in user_input_lower:
                score += 5
        
        elif intent == "marketing_copy":
            # Enhanced marketing context detection
            marketing_indicators = ["ë§ˆì¼€íŒ…", "ê´‘ê³ ", "í™ë³´", "ë¸Œëœë”©", "marketing", "advertising", "promotion", "branding"]
            if any(indicator in context_text for indicator in marketing_indicators):
                score += 6
            # Check for emotional/people-focused context
            if any(word in context_text for word in ["ê°ì„±", "ìê·¹", "ì‚¬ëŒ", "ê³ ê°", "emotion", "stimulate", "people", "customer"]):
                score += 5
        
        elif intent == "content_creation":
            # Enhanced content creation context
            content_indicators = ["ì½˜í…ì¸ ", "ê¸€", "ì‘ì„±", "content", "writing", "article", "post"]
            if any(indicator in context_text for indicator in content_indicators):
                score += 5
            # Check for writing request patterns
            if any(word in user_input_lower for word in ["ê·¸ëƒ¥", "ì¨ì¤˜", "just", "write"]):
                score += 4
        
        elif intent == "decision_making":
            # Enhanced decision-making context
            decision_indicators = ["í• ê¹Œ", "í•´ì•¼ í• ê¹Œ", "ì–´ë–»ê²Œ", "ì‹œë„", "í•´ë³¼ê¹Œ", "should i", "how", "try", "do it"]
            if any(indicator in context_text for indicator in decision_indicators):
                score += 5
            # Check for judgment/decision context
            if any(word in context_text for word in ["íŒë‹¨", "ê²°ì •", "judgment", "decision"]):
                score += 3
        
        elif intent == "trend_verification":
            # Enhanced trend verification context
            trend_indicators = ["ëŒ€ì„¸", "ìš”ì¦˜", "íŠ¸ë Œë“œ", "trend", "popular", "hot", "viral"]
            if any(indicator in context_text for indicator in trend_indicators):
                score += 4
            # Check for popularity/fashion context
            if any(word in context_text for word in ["ì¸ê¸°", "ìœ í–‰", "popularity", "fashion"]):
                score += 3
        
        elif intent == "casual_opinion":
            # Enhanced casual opinion context
            opinion_indicators = ["ê´œì°®ì•„", "ëŒ€ë°•", "ì¢‹ì•„", "cool", "awesome", "great", "nice"]
            if any(indicator in context_text for indicator in opinion_indicators):
                score += 4
            # Check for opinion/evaluation context
            if any(word in context_text for word in ["ì˜ê²¬", "í‰ê°€", "opinion", "evaluation"]):
                score += 3
        
        intent_scores[intent] = score
    
    # Find the highest scoring intent with reclassification logic
    if intent_scores:
        best_intent = max(intent_scores, key=intent_scores.get)
        if intent_scores[best_intent] > 0:
            config = intent_mapping[best_intent]
            return (
                best_intent, 
                config["korean_classification"], 
                config["description"],
                config.get("tone", "genuine"),
                config.get("style", "informative"),
                config.get("audience", "general")
            )
    
    # Default fallback with enhanced context
    return (
        "general_inquiry", 
        "ì¼ë°˜ì ì¸ ë¬¸ì˜", 
        "ì¼ë°˜ì ì¸ ì •ë³´ë‚˜ ê°€ì´ë“œ ìš”ì²­",
        "genuine",
        "informative", 
        "general"
    )

def format_chat_history(chat_history: list) -> str:
    """
    ì±„íŒ… íˆìŠ¤í† ë¦¬ë¥¼ í¬ë§·íŒ…í•˜ì—¬ ë§¥ë½ ì •ë³´ë¥¼ ì œê³µí•©ë‹ˆë‹¤.
    
    Args:
        chat_history (list): ì±„íŒ… íˆìŠ¤í† ë¦¬ ë¦¬ìŠ¤íŠ¸
        
    Returns:
        str: í¬ë§·íŒ…ëœ ì±„íŒ… íˆìŠ¤í† ë¦¬
    """
    if not chat_history:
        return "ì´ì „ ëŒ€í™” ê¸°ë¡ì´ ì—†ìŠµë‹ˆë‹¤."
    
    formatted_history = []
    for i, message in enumerate(chat_history[-3:], 1):  # ìµœê·¼ 3ê°œ ë©”ì‹œì§€ë§Œ ì‚¬ìš©
        if isinstance(message, dict):
            role = message.get('role', 'user')
            content = message.get('content', str(message))
        else:
            role = 'user'
            content = str(message)
        
        formatted_history.append(f"{i}. {role}: {content}")
    
    return "\n".join(formatted_history)

def fallback_prompt_from_topic(user_input: str) -> str:
    """
    Generate a purpose-driven fallback prompt based on the content of the user's input.
    This ensures meaningful guidance even when template matching fails.
    """
    lowered = user_input.lower()

    if "ì•„ì´ë””ì–´" in lowered or "idea" in lowered:
        return (
            "Please analyze the feasibility of the user's idea and draft a collaboration email. "
            "The response should include:\n"
            "- Summary of the idea\n"
            "- Feasibility and potential\n"
            "- Suggested collaboration plan\n"
            "- Expected outcomes\n"
            "- Next steps"
        )

    elif "ì‚¬ì—…ê³„íšì„œ" in lowered or "business plan" in lowered:
        return (
            "Please create a structured business plan draft that includes:\n"
            "- Executive summary\n"
            "- Market analysis\n"
            "- Value proposition\n"
            "- Roadmap\n"
            "- Risk and budget"
        )

    elif "ì œì•ˆì„œ" in lowered or "proposal" in lowered:
        return (
            "Please draft a public-sector or funding proposal including:\n"
            "- Project overview\n"
            "- Goals and objectives\n"
            "- Implementation strategy\n"
            "- Policy alignment\n"
            "- Impact and sustainability"
        )

    else:
        return (
            "Please interpret the user's request and generate a useful response "
            "using an appropriate prompt format. Include reasoning if needed."
        )

def sanitize_prompt(user_input: str) -> str:
    """
    ì‚¬ìš©ì ì…ë ¥ì„ ì •ë¦¬í•©ë‹ˆë‹¤.
    
    Args:
        user_input (str): ì‚¬ìš©ì ì…ë ¥
        
    Returns:
        str: ì •ë¦¬ëœ í”„ë¡¬í”„íŠ¸
    """
    # ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜
    if not isinstance(user_input, str):
        user_input = str(user_input)
    
    # ê¸°ë³¸ ì •ë¦¬
    user_input = user_input.strip().strip('"""')
    
    # ë”°ì˜´í‘œ ì •ê·œí™”
    if '"' in user_input or """ in user_input or """ in user_input:
        user_input = user_input.replace(""", "\"").replace(""", "\"")
    
    # ì›ë³¸ ì…ë ¥ ë°˜í™˜ (fallback ì œê±°)
    return user_input

def generate_prompt(intent: str, user_input: str, tone: str = "genuine", tense: str = "present", audience: str = "review panel") -> str:
    """
    ì˜ë„ì™€ ì‚¬ìš©ì ì…ë ¥ì„ ê¸°ë°˜ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    PromptOS ì›ì¹™: ì ˆëŒ€ ì‹¤íŒ¨í•˜ì§€ ì•ŠìŒ - LLM fallbackì´ ê¸°ë³¸ ë™ì‘
    
    Args:
        intent (str): ë¶„ë¥˜ëœ ì˜ë„
        user_input (str): ì‚¬ìš©ì ì…ë ¥
        tone (str): í†¤ (genuine, formal, casual)
        tense (str): ì‹œì œ (present, past, future)
        audience (str): ëŒ€ìƒ (review panel, customer, expert, student, government)
        
    Returns:
        str: ìƒì„±ëœ í”„ë¡¬í”„íŠ¸
    """
    # ì˜ë„ë³„ í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ (ê¸°ë³¸ í…œí”Œë¦¿)
    templates = {
        "business_plan": f"""
ì‚¬ìš©ìê°€ "{user_input}"ë¥¼ ì‘ì„±í•˜ê³ ì í•©ë‹ˆë‹¤.
ë‹¤ìŒ êµ¬ì¡°ì— ë”°ë¼ ì²´ê³„ì ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:

ğŸ“Œ ì‚¬ì—… ê°œìš”
- ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ê³¼ í•µì‹¬ ê°€ì¹˜ ì œì•ˆ
- ì‚¬ì—…ì˜ ëª©ì ê³¼ ë¹„ì „

ğŸ“Š ì‹œì¥ ë¶„ì„  
- ì‹œì¥ í˜„í™©ê³¼ ê·œëª¨
- ê²½ìŸì‚¬ ë¶„ì„ê³¼ ì°¨ë³„í™” í¬ì¸íŠ¸

ğŸ½ï¸ ì„œë¹„ìŠ¤ ì„¤ëª…
- í•µì‹¬ ì œí’ˆ/ì„œë¹„ìŠ¤ ìƒì„¸ ì„¤ëª…
- ê³ ê° ê°€ì¹˜ì™€ í˜œíƒ

ğŸ“ˆ ì‹¤í–‰ ê³„íš
- ë‹¨ê³„ë³„ ì‹¤í–‰ ì „ëµ
- ìì› ë° ì˜ˆì‚° ê³„íš

ğŸ¯ ê¸°ëŒ€ íš¨ê³¼
- ì˜ˆìƒ ì„±ê³¼ ë° ì§€í‘œ
- ì‚¬íšŒì /ê²½ì œì  ê¸°ì—¬ë„

ì „ë¬¸ì ì´ê³  ê²©ì‹ ìˆëŠ” í•œê¸€ ë³´ê³ ì„œ í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
""",
        "collaboration_email": f"""
ì‚¬ìš©ìê°€ "{user_input}"ì— ëŒ€í•œ í˜‘ì—… ì´ë©”ì¼ì„ ì‘ì„±í•˜ê³ ì í•©ë‹ˆë‹¤.
ë‹¤ìŒ ìš”ì†Œë¥¼ í¬í•¨í•˜ì—¬ ì „ë¬¸ì ì´ê³  ì¹œê·¼í•œ í†¤ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:

ğŸ“§ ì´ë©”ì¼ êµ¬ì¡°:
- ì¸ì‚¬ë§
- í˜‘ì—… ì œì•ˆ ë°°ê²½
- êµ¬ì²´ì ì¸ í˜‘ì—… ë°©ì•ˆ
- ê¸°ëŒ€ íš¨ê³¼
- ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ
- ë§ˆë¬´ë¦¬ ì¸ì‚¬

ì •ì¤‘í•˜ê³  ì„¤ë“ë ¥ ìˆëŠ” í†¤ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
""",
        "customer_reply": f"""
ì‚¬ìš©ìê°€ "{user_input}"ì— ëŒ€í•œ ê³ ê° ì‘ëŒ€ë¥¼ ì‘ì„±í•˜ê³ ì í•©ë‹ˆë‹¤.
ë‹¤ìŒ ì›ì¹™ì— ë”°ë¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

ğŸ’¬ ì‘ëŒ€ ì›ì¹™:
- ê³µê°ê³¼ ì´í•´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ë‹µë³€
- êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ í•´ê²°ì±… ì œì‹œ
- ì •ì¤‘í•˜ê³  ì¹œê·¼í•œ í†¤ ìœ ì§€
- ì¶”ê°€ ë¬¸ì˜ì— ëŒ€í•œ ê°œë°©ì  íƒœë„

ê³ ê°ì˜ ë§Œì¡±ë„ë¥¼ ë†’ì¼ ìˆ˜ ìˆëŠ” ì „ë¬¸ì ì¸ ì‘ëŒ€ë¬¸ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
""",
        "summary": f"""
ì‚¬ìš©ìê°€ "{user_input}"ì— ëŒ€í•œ ìš”ì•½ì„ ì‘ì„±í•˜ê³ ì í•©ë‹ˆë‹¤.
ë‹¤ìŒ ê¸°ì¤€ì— ë”°ë¼ ìš”ì•½í•´ì£¼ì„¸ìš”:

ğŸ“‹ ìš”ì•½ ê¸°ì¤€:
- í•µì‹¬ ë‚´ìš© ì¶”ì¶œ
- ë…¼ë¦¬ì  êµ¬ì¡° ìœ ì§€
- ëª…í™•í•˜ê³  ê°„ê²°í•œ í‘œí˜„
- ì¤‘ìš”ë„ì— ë”°ë¥¸ ìš°ì„ ìˆœìœ„

ì „ë¬¸ì ì´ê³  ê°ê´€ì ì¸ ìš”ì•½ë¬¸ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
""",
        "complaint": f"""
ì‚¬ìš©ìê°€ "{user_input}"ì— ëŒ€í•œ ë¶ˆë§Œ ì‚¬í•­ì„ ì‘ì„±í•˜ê³ ì í•©ë‹ˆë‹¤.
ë‹¤ìŒ ì›ì¹™ì— ë”°ë¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

ğŸ“ ë¶ˆë§Œ ì‚¬í•­ ì‘ì„± ì›ì¹™:
- êµ¬ì²´ì ì´ê³  ê°ê´€ì ì¸ ì‚¬ì‹¤ ê¸°ìˆ 
- ê°ì •ì  í‘œí˜„ ìµœì†Œí™”
- ê±´ì„¤ì ì¸ ê°œì„  ë°©ì•ˆ ì œì‹œ
- ì „ë¬¸ì ì´ê³  ì •ì¤‘í•œ í†¤ ìœ ì§€

ë¬¸ì œ í•´ê²°ì„ ìœ„í•œ ê±´ì„¤ì ì¸ ì˜ê²¬ì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
""",
        "self_intro": f"""
ì‚¬ìš©ìê°€ "{user_input}"ì— ëŒ€í•œ ìê¸°ì†Œê°œë¥¼ ì‘ì„±í•˜ê³ ì í•©ë‹ˆë‹¤.
ë‹¤ìŒ ìš”ì†Œë¥¼ í¬í•¨í•˜ì—¬ ì‘ì„±í•´ì£¼ì„¸ìš”:

ğŸ‘¤ ìê¸°ì†Œê°œ êµ¬ì„±:
- ì¸ì‚¬ë§
- ì£¼ìš” ê²½ë ¥ ë° ì „ë¬¸ ë¶„ì•¼
- í•µì‹¬ ì—­ëŸ‰ê³¼ ê°•ì 
- ëª©í‘œ ë° ë¹„ì „
- ë§ˆë¬´ë¦¬

ìì‹ ê° ìˆê³  ì „ë¬¸ì ì¸ ìê¸°ì†Œê°œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
""",
        "etc": f"""
ì‚¬ìš©ìê°€ "{user_input}"ì— ëŒ€í•œ ë‚´ìš©ì„ ì‘ì„±í•˜ê³ ì í•©ë‹ˆë‹¤.
ë‹¤ìŒ ê¸°ì¤€ì— ë”°ë¼ ì‘ì„±í•´ì£¼ì„¸ìš”:

ğŸ“ ì‘ì„± ê¸°ì¤€:
- ëª…í™•í•˜ê³  êµ¬ì¡°í™”ëœ ë‚´ìš©
- ì ì ˆí•œ í†¤ê³¼ ìŠ¤íƒ€ì¼
- ë…ì ì¹œí™”ì ì¸ í‘œí˜„
- ì „ë¬¸ì„±ê³¼ ê°€ë…ì„±ì˜ ê· í˜•

ìš”ì²­ì‚¬í•­ì— ë§ëŠ” ì „ë¬¸ì ì¸ ë‚´ìš©ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
"""
    }
    
    # 1. ê¸°ë³¸ í…œí”Œë¦¿ì—ì„œ ì°¾ê¸°
    template = templates.get(intent)
    
    # 2. í…œí”Œë¦¿ì´ ì—†ìœ¼ë©´ ëª©ì  ì§€í–¥ì  fallback ì‚¬ìš©
    if not template:
        print(f"[Fallback Triggered] No template for intent: {intent}. Using topic-based fallback.")
        
        # í‚¤ì›Œë“œ ê¸°ë°˜ ëª©ì  ì§€í–¥ì  fallback í”„ë¡¬í”„íŠ¸ ìƒì„±
        fallback_prompt = fallback_prompt_from_topic(user_input)
        
        try:
            # LLM í˜¸ì¶œí•˜ì—¬ ìµœì¢… ì‘ë‹µ ìƒì„±
            response = call_llm_openrouter(fallback_prompt)
            print(f"[Topic-Based Fallback Success] Generated response for user input: {user_input[:50]}...")
            return response
        except Exception as e:
            print(f"[Topic-Based Fallback Failed] Error: {e}. Using default template.")
            # LLM í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©
            return templates["etc"]
    
    return template

def extract_conditions(user_input: str) -> dict:
    """
    ì‚¬ìš©ì ì…ë ¥ì—ì„œ tone, tense, audience ì¡°ê±´ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
    """
    # ê¸°ë³¸ê°’ ì„¤ì • (ì‹œìŠ¤í…œ ì§€ì¹¨ì— ë”°ë¼)
    conditions = {
        "tone": "genuine",
        "tense": "present", 
        "audience": "review panel"
    }
    
    # ì‚¬ìš©ì ì…ë ¥ì—ì„œ í‚¤ì›Œë“œ ê¸°ë°˜ìœ¼ë¡œ ì¡°ê±´ ì¶”ì¶œ
    user_input_lower = user_input.lower()
    
    # í†¤ ì¶”ì¶œ
    if any(word in user_input_lower for word in ["ì •ì¤‘í•œ", "ê³µì‹", "formal", "ë¹„ì¦ˆë‹ˆìŠ¤", "professional", "business"]):
        conditions["tone"] = "formal"
    elif any(word in user_input_lower for word in ["ì¹œê·¼í•œ", "ìºì£¼ì–¼", "informal", "í¸ì•ˆí•œ", "casual", "friendly"]):
        conditions["tone"] = "casual"
    elif any(word in user_input_lower for word in ["ì§„ì •ì„±", "genuine", "authentic", "sincere"]):
        conditions["tone"] = "genuine"
    
    # ì‹œì œ ì¶”ì¶œ
    if any(word in user_input_lower for word in ["ê³¼ê±°", "í–ˆì–´", "í–ˆë˜", "past", "completed", "finished"]):
        conditions["tense"] = "past"
    elif any(word in user_input_lower for word in ["ë¯¸ë˜", "í• ê±°ì•¼", "ì˜ˆì •", "future", "will", "going to"]):
        conditions["tense"] = "future"
    elif any(word in user_input_lower for word in ["í˜„ì¬", "ì§€ê¸ˆ", "present", "current", "now"]):
        conditions["tense"] = "present"
    
    # ì²­ì¤‘ ì¶”ì¶œ
    if any(word in user_input_lower for word in ["ê³ ê°", "customer", "í´ë¼ì´ì–¸íŠ¸", "client"]):
        conditions["audience"] = "customer"
    elif any(word in user_input_lower for word in ["ì „ë¬¸ê°€", "expert", "ê°œë°œì", "ì—”ì§€ë‹ˆì–´", "specialist"]):
        conditions["audience"] = "expert"
    elif any(word in user_input_lower for word in ["í•™ìƒ", "ì´ˆë³´ì", "beginner", "student"]):
        conditions["audience"] = "student"
    elif any(word in user_input_lower for word in ["ì •ë¶€", "government", "ê³µë¬´ì›", "official"]):
        conditions["audience"] = "government"
    elif any(word in user_input_lower for word in ["ê²€í† ", "review", "í‰ê°€", "evaluation", "ì‹¬ì‚¬", "panel"]):
        conditions["audience"] = "review panel"
    
    return conditions

def process_user_request(user_input: str, chat_history: list = None) -> dict:
    """
    ì‚¬ìš©ì ìš”ì²­ì„ ì²˜ë¦¬í•˜ì—¬ ì˜ë„ ë¶„ë¥˜ì™€ í‘œì¤€í™”ëœ í”„ë¡¬í”„íŠ¸ ì§€ì‹œì‚¬í•­ì„ ìƒì„±í•©ë‹ˆë‹¤.
    
    ğŸ§  [ì»¤ì„œ ì§€ì‹œê¸€: ëª©ì  ê¸°ë°˜ í…œí”Œë¦¿ ì‹œìŠ¤í…œ ì´ˆê³ ë„í™”]
    - ëª…ì‹œì  ëª©ì ì´ ìˆëŠ” ë°œí™” â†’ ì™„ì „í•œ intent í…œí”Œë¦¿ ë§¤ì¹­ í›„ ê³ ì • êµ¬ì¡° ê¸°ë°˜ ì‘ë‹µ
    - ëª…ì‹œì  ëª©ì ì´ ì—†ëŠ” ë°œí™” â†’ LLM ëª©ì  ì¶”ë¡  + ì‚¬ìš©ì ë³´ì™„ ì§ˆì˜ í›„ ì¶œë ¥
    - ì¶œë ¥ì€ í•­ìƒ í•œêµ­ì–´, ì§€ì‹œë¬¸ì€ ì˜ë¬¸ ì½”ë“œë¡œ
    
    Args:
        user_input (str): ì‚¬ìš©ì ì…ë ¥
        chat_history (list): ì±„íŒ… íˆìŠ¤í† ë¦¬ (ì„ íƒì‚¬í•­)
        
    Returns:
        dict: ì²˜ë¦¬ ê²°ê³¼ (intent, prompt_instruction, original_input, conditions, intent_analysis, confidence_score)
    """
    try:
        # ì…ë ¥ ì •ë¦¬
        cleaned_input = sanitize_prompt(user_input)
        logger.info(f"ì…ë ¥ ì •ë¦¬ ì™„ë£Œ: {cleaned_input[:50]}...")
        
        # ğŸ§  ëª©ì  ê¸°ë°˜ í…œí”Œë¦¿ ì‹œìŠ¤í…œ ì‚¬ìš©
        purpose_system = get_purpose_based_template_system()
        purpose_result = purpose_system.process_user_request(cleaned_input, chat_history)
        
        # ëª©ì  ê¸°ë°˜ ì‹œìŠ¤í…œì—ì„œ ëª…í™•í•œ ë§¤ì¹­ì´ ëœ ê²½ìš°
        if purpose_result["template_matched"]:
            logger.info(f"ëª©ì  ê¸°ë°˜ í…œí”Œë¦¿ ë§¤ì¹­ ì„±ê³µ: {purpose_result['intent']}")
            
            return {
                "intent": purpose_result["intent"],
                "prompt_instruction": purpose_result["prompt_instruction"],
                "original_input": user_input,
                "cleaned_input": cleaned_input,
                "conditions": {"tone": "genuine", "tense": "present", "audience": "review panel"},
                "intent_analysis": {"intent": purpose_result["intent"], "description": "ëª©ì  ê¸°ë°˜ í…œí”Œë¦¿ ë§¤ì¹­"},
                "confidence_score": purpose_result["confidence_score"],
                "method": purpose_result["method"],
                "context_used": False,
                "step": purpose_result["step"],
                "additional_questions": purpose_result["additional_questions"]
            }
        
        # ëª©ì ì´ ë¶ˆëª…í™•í•œ ê²½ìš° ê¸°ì¡´ ë¡œì§ ì‚¬ìš©
        else:
            logger.info("ëª©ì  ê¸°ë°˜ ë§¤ì¹­ ì‹¤íŒ¨, ê¸°ì¡´ ë¡œì§ ì‚¬ìš©")
            
            # ê¸°ì¡´ ì˜ë„ ë¶„ë¥˜ (í…œí”Œë¦¿ ë§¤ì¹­ìš©)
            template_intent = classify_intent(cleaned_input)
            logger.info(f"ê¸°ì¡´ í…œí”Œë¦¿ ì˜ë„ ë¶„ë¥˜ ê²°ê³¼: {template_intent}")
            
            # Intent & Purpose Extraction (ëª¨í˜¸í•œ ì…ë ¥ ë¶„ì„)
            intent_analysis = extract_intent_and_purpose(cleaned_input, chat_history)
            logger.info(f"Intent & Purpose ë¶„ì„: {intent_analysis['intent']}")
            
            # ì‹ ë¢°ë„ í‰ê°€
            confidence_score = evaluate_intent_confidence(template_intent, intent_analysis, cleaned_input)
            logger.info(f"ì˜ë„ ë¶„ë¥˜ ì‹ ë¢°ë„: {confidence_score}")
            
            # ì‹ ë¢°ë„ê°€ ë†’ì€ ê²½ìš° ê¸°ì¡´ í…œí”Œë¦¿ ì‚¬ìš©
            if confidence_score >= 0.7:
                logger.info("ê¸°ì¡´ í…œí”Œë¦¿ ë§¤ì¹­ ì‚¬ìš©")
                conditions = extract_conditions(cleaned_input)
                prompt_instruction = generate_standardized_prompt_instruction(cleaned_input, intent_analysis, chat_history)
                
                return {
                    "intent": template_intent,
                    "prompt_instruction": prompt_instruction,
                    "original_input": user_input,
                    "cleaned_input": cleaned_input,
                    "conditions": conditions,
                    "intent_analysis": intent_analysis,
                    "confidence_score": confidence_score,
                    "method": "legacy_template_matching",
                    "context_used": False,
                    "step": "Step 2: Legacy Template Matching",
                    "additional_questions": []
                }
            
            # ì‹ ë¢°ë„ê°€ ë‚®ê³  ì±„íŒ… íˆìŠ¤í† ë¦¬ê°€ ìˆëŠ” ê²½ìš° LLM ê¸°ë°˜ ì¶”ë¡ 
            elif chat_history:
                logger.info("LLM ê¸°ë°˜ ì˜ë„ ì¶”ë¡  ìˆ˜í–‰")
                advanced_analysis = advanced_intent_reconstruction(cleaned_input, chat_history)
                
                final_intent = advanced_analysis["intent"]
                final_intent_analysis = {
                    "intent": final_intent,
                    "korean_classification": advanced_analysis.get("korean_response", "ê³ ê¸‰ ë¶„ì„ ê²°ê³¼"),
                    "description": f"ê³ ê¸‰ LLM ë¶„ì„ì„ í†µí•œ {final_intent} ì˜ë„ ì¶”ë¡ ",
                    "tone": advanced_analysis["conditions"]["tone"],
                    "style": "informative",
                    "audience": advanced_analysis["conditions"]["audience"]
                }
                prompt_instruction = generate_standardized_prompt_instruction(cleaned_input, final_intent_analysis, chat_history)
                
                return {
                    "intent": final_intent,
                    "prompt_instruction": prompt_instruction,
                    "original_input": user_input,
                    "cleaned_input": cleaned_input,
                    "conditions": advanced_analysis["conditions"],
                    "intent_analysis": intent_analysis,
                    "confidence_score": confidence_score,
                    "advanced_analysis": advanced_analysis,
                    "method": "llm_purpose_inference",
                    "context_used": True,
                    "user_message": "ì‚¬ìš©ìì˜ ìš”ì²­ì´ ëª…í™•í•˜ì§€ ì•Šì§€ë§Œ, ì´ì „ ëŒ€í™” íë¦„ì„ ê¸°ë°˜ìœ¼ë¡œ ëª©ì ì„ ì¶”ë¡ í•˜ê³  ê°€ì¥ ì ì ˆí•œ ë°©ì‹ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.",
                    "step": "Step 3: Purpose Inference",
                    "additional_questions": purpose_result["additional_questions"]
                }
            
            # ìµœì¢… fallback
            else:
                logger.info("ìµœì¢… fallback ì‚¬ìš©")
                fallback_instruction = generate_fallback_instruction(cleaned_input, intent_analysis)
                
                return {
                    "intent": "general_inquiry",
                    "prompt_instruction": fallback_instruction,
                    "original_input": user_input,
                    "cleaned_input": cleaned_input,
                    "conditions": {"tone": "genuine", "tense": "present", "audience": "review panel"},
                    "intent_analysis": intent_analysis,
                    "confidence_score": confidence_score,
                    "method": "final_fallback",
                    "context_used": False,
                    "user_message": "ì‚¬ìš©ìì˜ ìš”ì²­ì´ ëª…í™•í•˜ì§€ ì•Šì§€ë§Œ, ê°€ì¥ ì ì ˆí•œ ë°©ì‹ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.",
                    "step": "Step 4: Final Fallback",
                    "additional_questions": purpose_result["additional_questions"]
                }
        
    except Exception as e:
        logger.error(f"ìš”ì²­ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œì—ë„ ê¸°ë³¸ê°’ìœ¼ë¡œ fallback
        fallback_intent_analysis = extract_intent_and_purpose(user_input)
        fallback_instruction = generate_fallback_instruction(user_input, fallback_intent_analysis)
        
        return {
            "intent": "etc",
            "prompt_instruction": fallback_instruction,
            "original_input": user_input,
            "cleaned_input": user_input,
            "conditions": {"tone": "genuine", "tense": "present", "audience": "review panel"},
            "intent_analysis": fallback_intent_analysis,
            "confidence_score": 0.0,
            "error": str(e),
            "method": "error_fallback",
            "context_used": False,
            "user_message": "ì‚¬ìš©ìì˜ ìš”ì²­ì´ ëª…í™•í•˜ì§€ ì•Šì•„, ê´€ë ¨ëœ ë§¥ë½ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤.",
            "step": "Error Fallback",
            "additional_questions": ["ì–´ë–¤ ì¢…ë¥˜ì˜ ë„ì›€ì´ í•„ìš”í•˜ì‹ ê°€ìš”?"]
        }

def evaluate_intent_confidence(template_intent: str, intent_analysis: dict, user_input: str) -> float:
    """
    ì˜ë„ ë¶„ë¥˜ì˜ ì‹ ë¢°ë„ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.
    [ğŸ“Œ REFINED CURSOR INSTRUCTION] í–¥ìƒëœ ì‹ ë¢°ë„ í‰ê°€
    
    Args:
        template_intent (str): í…œí”Œë¦¿ ê¸°ë°˜ ì˜ë„ ë¶„ë¥˜ ê²°ê³¼
        intent_analysis (dict): Intent & Purpose ë¶„ì„ ê²°ê³¼
        user_input (str): ì‚¬ìš©ì ì…ë ¥
        
    Returns:
        float: ì‹ ë¢°ë„ ì ìˆ˜ (0.0 ~ 1.0)
    """
    confidence_score = 0.0
    input_lower = user_input.lower()
    
    # 1. í…œí”Œë¦¿ ì˜ë„ ë¶„ë¥˜ ì‹ ë¢°ë„ (0.0 ~ 0.3)
    if template_intent != "etc":
        confidence_score += 0.3
    elif template_intent == "etc":
        confidence_score += 0.1  # ê¸°ë³¸ ì ìˆ˜
    
    # 2. Intent & Purpose ë¶„ì„ ì‹ ë¢°ë„ (0.0 ~ 0.3)
    if intent_analysis["intent"] != "general_inquiry":
        confidence_score += 0.3
    elif intent_analysis["intent"] == "general_inquiry":
        confidence_score += 0.1  # ê¸°ë³¸ ì ìˆ˜
    
    # 3. ì…ë ¥ ê¸¸ì´ ë° ë³µì¡ì„± (0.0 ~ 0.15)
    input_length = len(user_input.strip())
    if input_length > 20:
        confidence_score += 0.15
    elif input_length > 10:
        confidence_score += 0.1
    elif input_length > 5:
        confidence_score += 0.05
    
    # 4. ëª…í™•í•œ í‚¤ì›Œë“œ ë§¤ì¹­ (0.0 ~ 0.2)
    clear_keywords = {
        "business": ["ì‚¬ì—…ê³„íšì„œ", "ë¹„ì¦ˆë‹ˆìŠ¤", "ì°½ì—…", "business plan", "startup", "company"],
        "marketing": ["ë§ˆì¼€íŒ…", "ê´‘ê³ ", "í™ë³´", "ë¸Œëœë”©", "marketing", "advertising", "promotion"],
        "proposal": ["ì œì•ˆì„œ", "ì œì•ˆ", "proposal", "suggestion", "recommendation"],
        "summary": ["ìš”ì•½", "ì •ë¦¬", "summary", "summarize", "brief"],
        "self_intro": ["ìê¸°ì†Œê°œ", "ì´ë ¥ì„œ", "resume", "introduction"],
        "customer": ["ê³ ê°", "customer", "client", "service"],
        "content": ["ì½˜í…ì¸ ", "ê¸€", "ì‘ì„±", "content", "writing", "article"],
        "investor": ["IR", "íˆ¬ìì", "íˆ¬ì", "investor", "investment", "ì´ˆì•ˆ", "draft"]
    }
    
    keyword_matches = 0
    for category, keywords in clear_keywords.items():
        if any(keyword in input_lower for keyword in keywords):
            keyword_matches += 1
    
    if keyword_matches >= 2:
        confidence_score += 0.2
    elif keyword_matches == 1:
        confidence_score += 0.1
    
    # 5. ëª¨í˜¸í•œ íŒ¨í„´ ê°ì§€ (íŒ¨ë„í‹°: -0.0 ~ -0.2) - íŒ¨ë„í‹° ì™„í™”
    ambiguous_patterns = {
        "high_ambiguity": ["ê·¸ëƒ¥", "ì´ê±°", "ìš”ì¦˜", "ëŒ€ì„¸", "ê´œì°®ì•„", "ëŒ€ë°•", "í• ê¹Œ", "í˜•", "bro"],
        "medium_ambiguity": ["just", "this", "trend", "cool", "awesome", "should i", "is this ok"],
        "low_ambiguity": ["ì‚¬ëŒ", "ê°ì„±", "ìê·¹", "ì¨ì¤˜", "people", "emotion", "stimulate", "write"]
    }
    
    ambiguity_penalty = 0.0
    for level, patterns in ambiguous_patterns.items():
        if any(pattern in input_lower for pattern in patterns):
            if level == "high_ambiguity":
                ambiguity_penalty += 0.2  # 0.3ì—ì„œ 0.2ë¡œ ì™„í™”
            elif level == "medium_ambiguity":
                ambiguity_penalty += 0.1  # 0.2ì—ì„œ 0.1ë¡œ ì™„í™”
            elif level == "low_ambiguity":
                ambiguity_penalty += 0.05  # 0.05ì—ì„œ 0.05ë¡œ ìœ ì§€
    
    confidence_score -= ambiguity_penalty
    
    # 6. ë¬¸ì¥ êµ¬ì¡° ë° ì™„ì„±ë„ (0.0 ~ 0.05)
    if user_input.endswith(('.', '!', '?')):
        confidence_score += 0.05
    
    # 7. ë§¥ë½ ì¸ì‹ ê°€ëŠ¥ì„± (0.0 ~ 0.05)
    context_indicators = ["ì´ì „", "ì•ì„œ", "ìœ„ì—ì„œ", "ì•ì˜", "ì´ì „ì—", "before", "previous", "above"]
    if any(indicator in input_lower for indicator in context_indicators):
        confidence_score += 0.05
    
    # 8. ì˜ë„ ë¶„ë¥˜ ì¼ì¹˜ë„ (0.0 ~ 0.1)
    if template_intent != "etc" and intent_analysis["intent"] != "general_inquiry":
        # ë‘ ë¶„ë¥˜ ê²°ê³¼ê°€ ëª¨ë‘ êµ¬ì²´ì ì¸ ê²½ìš°
        if template_intent == intent_analysis["intent"]:
            confidence_score += 0.1
        elif any(keyword in template_intent for keyword in intent_analysis["intent"].split('_')):
            confidence_score += 0.05
    
    # ìµœì¢… ì‹ ë¢°ë„ ì ìˆ˜ ì •ê·œí™” (0.0 ~ 1.0)
    final_confidence = max(0.0, min(confidence_score, 1.0))
    
    # ë¡œê¹…
    logger.info(f"ì‹ ë¢°ë„ í‰ê°€ ìƒì„¸:")
    logger.info(f"  - í…œí”Œë¦¿ ì˜ë„: {template_intent}")
    logger.info(f"  - Intent & Purpose: {intent_analysis['intent']}")
    logger.info(f"  - ì…ë ¥ ê¸¸ì´: {input_length}")
    logger.info(f"  - í‚¤ì›Œë“œ ë§¤ì¹­: {keyword_matches}")
    logger.info(f"  - ëª¨í˜¸ì„± íŒ¨ë„í‹°: {ambiguity_penalty}")
    logger.info(f"  - ìµœì¢… ì‹ ë¢°ë„: {final_confidence:.3f}")
    
    return final_confidence

def advanced_intent_reconstruction(user_input: str, chat_history: list) -> dict:
    """
    [ğŸ“Œ REFINED CURSOR INSTRUCTION] ê³ ê¸‰ LLM ê¸°ë°˜ ì˜ë„ ì¬êµ¬ì„±
    
    If the user's intent is **not clearly classifiable**, refer to prior messages (chat history) 
    to infer their likely goal. Reclassify the intent based on inferred purpose 
    (e.g., if "Make an IR draft" is detected, override 'general_inquiry' with 'investor_IR_document').
    
    Use the inferred intent to select or construct the appropriate system prompt template.
    Avoid generic fallback templates unless absolutely necessary.
    Always match prompt tone, style, and structure to the purpose 
    (e.g., professional for investors, casual for friend advice).
    
    Args:
        user_input (str): í˜„ì¬ ì‚¬ìš©ì ì…ë ¥
        chat_history (list): ëŒ€í™” íˆìŠ¤í† ë¦¬
        
    Returns:
        dict: ê³ ê¸‰ ë¶„ì„ ê²°ê³¼
    """
    # ìµœê·¼ 3-5ê°œ ëŒ€í™”ë§Œ ì‚¬ìš©
    recent_context = format_chat_history(chat_history[-5:])
    
    # ê³ ê¸‰ LLM í”„ë¡¬í”„íŠ¸ êµ¬ì„± - ê°œì„ ëœ ì˜ë„ ì¬ë¶„ë¥˜ ë¡œì§
    advanced_prompt = f"""---
User input: {user_input}
Conversation context:
{recent_context}

Tasks:
a. Reconstruct user's true intent from context
b. Classify intent type (summary, decision, suggestion, etc.)
c. Suggest appropriate tone, tense, and audience
d. Generate the most relevant and natural response in Korean

ë¶„ì„ ì§€ì¹¨:
1. ëŒ€í™” ë§¥ë½ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ì‚¬ìš©ìì˜ ì‹¤ì œ ëª©ì ì„ íŒŒì•…
2. ëª¨í˜¸í•œ í‘œí˜„ì„ êµ¬ì²´ì ì´ê³  ì‹¤ìš©ì ì¸ ìš”ì²­ìœ¼ë¡œ í•´ì„
3. ì´ì „ ëŒ€í™”ì—ì„œ ì–¸ê¸‰ëœ ì£¼ì œë‚˜ ëª©ì ê³¼ ì—°ê²°
4. ì‚¬ìš©ìì˜ ìƒí™©ê³¼ ë°°ê²½ì„ ê³ ë ¤í•œ ë§ì¶¤í˜• ì‘ë‹µ êµ¬ì„±
5. í•œêµ­ì–´ ë¬¸í™”ì™€ ë§¥ë½ì„ ê³ ë ¤í•œ ìì—°ìŠ¤ëŸ¬ìš´ í‘œí˜„ ì‚¬ìš©
6. ì˜ë„ ì¬ë¶„ë¥˜: ë§¥ë½ì—ì„œ íŠ¹ì • ëª©ì ì´ ê°ì§€ë˜ë©´ ì ì ˆí•œ ì˜ë„ë¡œ ì¬ë¶„ë¥˜
   - IR/íˆ¬ìì ê´€ë ¨: investor_IR_document
   - ì‚¬ì—…ê³„íšì„œ ê´€ë ¨: business_plan
   - ë§ˆì¼€íŒ… ê´€ë ¨: marketing_copy
   - ì½˜í…ì¸  ì‘ì„±: content_creation
   - ì˜ì‚¬ê²°ì •: decision_making
   - íŠ¸ë Œë“œ ê²€ì¦: trend_verification
   - ìºì£¼ì–¼ ì˜ê²¬: casual_opinion

ì¶œë ¥ í˜•ì‹:
ì˜ë„ ë¶„ë¥˜: [intent_type]
í†¤: [tone]
ì‹œì œ: [tense]
ëŒ€ìƒ: [audience]
í•œêµ­ì–´ ì‘ë‹µ: [natural_korean_response]

ëª¨ë“  ì¶œë ¥ì€ ë°˜ë“œì‹œ í•œê¸€ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
ì‚¬ìš©ìì˜ ìš”ì²­ì´ ëª…í™•í•˜ì§€ ì•Šì§€ë§Œ, ì´ì „ ëŒ€í™” íë¦„ì„ ê¸°ë°˜ìœ¼ë¡œ ëª©ì ì„ ì¶”ë¡ í•˜ê³  ê°€ì¥ ì ì ˆí•œ ë°©ì‹ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í•©ë‹ˆë‹¤.
---"""

    try:
        # LLM í˜¸ì¶œí•˜ì—¬ ê³ ê¸‰ ë¶„ì„ ìˆ˜í–‰
        llm_response = call_llm_openrouter(advanced_prompt)
        
        # ì‘ë‹µ íŒŒì‹±
        parsed_response = parse_advanced_llm_response(llm_response)
        
        # ì‹ ë¢°ë„ ì¬í‰ê°€
        reconstructed_confidence = evaluate_reconstructed_confidence(
            user_input, chat_history, parsed_response
        )
        
        return {
            "intent": parsed_response.get("intent", "general_inquiry"),
            "llm_prompt": advanced_prompt,
            "llm_response": llm_response,
            "conditions": {
                "tone": parsed_response.get("tone", "genuine"),
                "tense": parsed_response.get("tense", "present"),
                "audience": parsed_response.get("audience", "review panel")
            },
            "korean_response": parsed_response.get("korean_response", ""),
            "confidence": reconstructed_confidence,
            "context_analysis": {
                "context_used": True,
                "context_length": len(recent_context),
                "reconstruction_method": "advanced_llm"
            }
        }
        
    except Exception as e:
        logger.error(f"ê³ ê¸‰ ì˜ë„ ì¬êµ¬ì„± ì¤‘ ì˜¤ë¥˜: {e}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ê¸°ë³¸ê°’ ë°˜í™˜
        return {
            "intent": "general_inquiry",
            "llm_prompt": advanced_prompt,
            "llm_response": "ì˜¤ë¥˜ë¡œ ì¸í•´ ê¸°ë³¸ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.",
            "conditions": {
                "tone": "genuine",
                "tense": "present", 
                "audience": "review panel"
            },
            "korean_response": f"ì‚¬ìš©ìì˜ ìš”ì²­ì´ ëª…í™•í•˜ì§€ ì•Šì•„, ê´€ë ¨ëœ ë§¥ë½ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤. '{user_input}'ì— ëŒ€í•œ ì‘ë‹µì„ ìƒì„±í•˜ëŠ” ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
            "confidence": 0.5,
            "context_analysis": {
                "context_used": True,
                "context_length": len(recent_context),
                "reconstruction_method": "error_fallback"
            }
        }

def generate_enhanced_fallback_prompt(user_input: str, intent_analysis: dict) -> str:
    """
    í–¥ìƒëœ fallback í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    ì±„íŒ… íˆìŠ¤í† ë¦¬ê°€ ì—†ì§€ë§Œ ì‹ ë¢°ë„ê°€ ë‚®ì€ ê²½ìš° ì‚¬ìš©ë©ë‹ˆë‹¤.
    
    Args:
        user_input (str): ì‚¬ìš©ì ì…ë ¥
        intent_analysis (dict): Intent & Purpose ë¶„ì„ ê²°ê³¼
        
    Returns:
        str: í–¥ìƒëœ fallback í”„ë¡¬í”„íŠ¸
    """
    # ì‚¬ìš©ì ì…ë ¥ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
    input_lower = user_input.lower()
    
    # í‚¤ì›Œë“œ ê¸°ë°˜ ëª©ì  ì¶”ë¡ 
    purpose_keywords = {
        "business": ["ì‚¬ì—…", "ë¹„ì¦ˆë‹ˆìŠ¤", "ì°½ì—…", "startup", "business", "company"],
        "marketing": ["ë§ˆì¼€íŒ…", "ê´‘ê³ ", "í™ë³´", "ë¸Œëœë”©", "marketing", "advertising"],
        "writing": ["ê¸€", "ì‘ì„±", "ì½˜í…ì¸ ", "writing", "content", "article"],
        "decision": ["ê²°ì •", "íŒë‹¨", "í• ê¹Œ", "decision", "choice", "should"],
        "analysis": ["ë¶„ì„", "ê²€í† ", "ë¦¬ë·°", "analysis", "review", "evaluate"],
        "summary": ["ìš”ì•½", "ì •ë¦¬", "summary", "summarize", "brief"],
        "proposal": ["ì œì•ˆ", "ì œì•ˆì„œ", "proposal", "suggestion", "recommendation"]
    }
    
    detected_purpose = "general"
    for purpose, keywords in purpose_keywords.items():
        if any(keyword in input_lower for keyword in keywords):
            detected_purpose = purpose
            break
    
    # ëª©ì ë³„ ë§ì¶¤í˜• í”„ë¡¬í”„íŠ¸ ìƒì„±
    purpose_prompts = {
        "business": f"""
ì‚¬ìš©ì ì…ë ¥: "{user_input}"

ë¶„ì„ëœ ì˜ë„: {intent_analysis.get('intent', 'business_plan')}
í•œêµ­ì–´ ë¶„ë¥˜: {intent_analysis.get('korean_classification', 'ì‚¬ì—… ê´€ë ¨ ìš”ì²­')}

ì‚¬ìš©ìì˜ ìš”ì²­ì´ ëª…í™•í•˜ì§€ ì•Šì§€ë§Œ, ì‚¬ì—…/ë¹„ì¦ˆë‹ˆìŠ¤ ë§¥ë½ìœ¼ë¡œ ì¶”ë¡ í•˜ì—¬ ê°€ì¥ ì ì ˆí•œ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.

ìš”êµ¬ì‚¬í•­:
1. ì‚¬ì—…ì  ê´€ì ì—ì„œ ì‹¤ìš©ì ì´ê³  êµ¬ì²´ì ì¸ ì¡°ì–¸ ì œê³µ
2. ì‹œì¥ ë¶„ì„, ìˆ˜ìµì„±, ë¦¬ìŠ¤í¬ ë“±ì„ ê³ ë ¤í•œ ì¢…í•©ì  í‰ê°€
3. ë‹¤ìŒ ë‹¨ê³„ë¥¼ ìœ„í•œ êµ¬ì²´ì ì¸ ì•¡ì…˜ í”Œëœ ì œì‹œ
4. ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ í•œêµ­ì–´ ì‘ë‹µ

ì¶œë ¥: í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê³  ì‹¤ìš©ì ì¸ ì‚¬ì—… ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”.
""",
        
        "marketing": f"""
ì‚¬ìš©ì ì…ë ¥: "{user_input}"

ë¶„ì„ëœ ì˜ë„: {intent_analysis.get('intent', 'marketing_copy')}
í•œêµ­ì–´ ë¶„ë¥˜: {intent_analysis.get('korean_classification', 'ë§ˆì¼€íŒ… ê´€ë ¨ ìš”ì²­')}

ì‚¬ìš©ìì˜ ìš”ì²­ì´ ëª…í™•í•˜ì§€ ì•Šì§€ë§Œ, ë§ˆì¼€íŒ…/í™ë³´ ë§¥ë½ìœ¼ë¡œ ì¶”ë¡ í•˜ì—¬ ê°€ì¥ ì ì ˆí•œ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.

ìš”êµ¬ì‚¬í•­:
1. íƒ€ê²Ÿ ê³ ê°ì¸µì„ ê³ ë ¤í•œ ë§ˆì¼€íŒ… ì „ëµ ì œì•ˆ
2. ê°ì„±ì ì´ê³  ì„¤ë“ë ¥ ìˆëŠ” ë©”ì‹œì§€ êµ¬ì„±
3. ë¸Œëœë“œ ì•„ì´ë´í‹°í‹°ì™€ ì¼ì¹˜í•˜ëŠ” í†¤ì•¤ë§¤ë„ˆ ì ìš©
4. êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ë§ˆì¼€íŒ… ì•„ì´ë””ì–´ ì œì‹œ

ì¶œë ¥: í•œêµ­ì–´ë¡œ ì°½ì˜ì ì´ê³  íš¨ê³¼ì ì¸ ë§ˆì¼€íŒ… ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”.
""",
        
        "writing": f"""
ì‚¬ìš©ì ì…ë ¥: "{user_input}"

ë¶„ì„ëœ ì˜ë„: {intent_analysis.get('intent', 'content_creation')}
í•œêµ­ì–´ ë¶„ë¥˜: {intent_analysis.get('korean_classification', 'ì½˜í…ì¸  ì‘ì„± ìš”ì²­')}

ì‚¬ìš©ìì˜ ìš”ì²­ì´ ëª…í™•í•˜ì§€ ì•Šì§€ë§Œ, ê¸€ì“°ê¸°/ì½˜í…ì¸  ì‘ì„± ë§¥ë½ìœ¼ë¡œ ì¶”ë¡ í•˜ì—¬ ê°€ì¥ ì ì ˆí•œ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.

ìš”êµ¬ì‚¬í•­:
1. ë…ìì¸µì— ë§ëŠ” ì ì ˆí•œ ìŠ¤íƒ€ì¼ê³¼ í†¤ ì„ íƒ
2. ëª…í™•í•˜ê³  í¥ë¯¸ë¡œìš´ êµ¬ì¡°ë¡œ ì½˜í…ì¸  êµ¬ì„±
3. í•µì‹¬ ë©”ì‹œì§€ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ì „ë‹¬í•˜ëŠ” í‘œí˜„ ì‚¬ìš©
4. SEOë‚˜ ê°€ë…ì„±ì„ ê³ ë ¤í•œ ìµœì í™” ì œì•ˆ

ì¶œë ¥: í•œêµ­ì–´ë¡œ ë§¤ë ¥ì ì´ê³  íš¨ê³¼ì ì¸ ì½˜í…ì¸  ì‘ì„± ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”.
""",
        
        "decision": f"""
ì‚¬ìš©ì ì…ë ¥: "{user_input}"

ë¶„ì„ëœ ì˜ë„: {intent_analysis.get('intent', 'decision_making')}
í•œêµ­ì–´ ë¶„ë¥˜: {intent_analysis.get('korean_classification', 'ì˜ì‚¬ê²°ì • ìš”ì²­')}

ì‚¬ìš©ìì˜ ìš”ì²­ì´ ëª…í™•í•˜ì§€ ì•Šì§€ë§Œ, ì˜ì‚¬ê²°ì •/íŒë‹¨ ë§¥ë½ìœ¼ë¡œ ì¶”ë¡ í•˜ì—¬ ê°€ì¥ ì ì ˆí•œ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.

ìš”êµ¬ì‚¬í•­:
1. ì¥ë‹¨ì ì„ ê°ê´€ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ì œì‹œ
2. ë¦¬ìŠ¤í¬ì™€ ê¸°íšŒë¥¼ ì¢…í•©ì ìœ¼ë¡œ í‰ê°€
3. ê°œì¸ì  ìƒí™©ê³¼ ëª©í‘œë¥¼ ê³ ë ¤í•œ ë§ì¶¤í˜• ì¡°ì–¸
4. êµ¬ì²´ì ì¸ íŒë‹¨ ê¸°ì¤€ê³¼ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ

ì¶œë ¥: í•œêµ­ì–´ë¡œ ì‹ ì¤‘í•˜ê³  ì‹¤ìš©ì ì¸ ì˜ì‚¬ê²°ì • ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”.
""",
        
        "analysis": f"""
ì‚¬ìš©ì ì…ë ¥: "{user_input}"

ë¶„ì„ëœ ì˜ë„: {intent_analysis.get('intent', 'feasibility_judgment')}
í•œêµ­ì–´ ë¶„ë¥˜: {intent_analysis.get('korean_classification', 'ë¶„ì„/ê²€í†  ìš”ì²­')}

ì‚¬ìš©ìì˜ ìš”ì²­ì´ ëª…í™•í•˜ì§€ ì•Šì§€ë§Œ, ë¶„ì„/ê²€í†  ë§¥ë½ìœ¼ë¡œ ì¶”ë¡ í•˜ì—¬ ê°€ì¥ ì ì ˆí•œ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.

ìš”êµ¬ì‚¬í•­:
1. ê°ê´€ì ì´ê³  ì²´ê³„ì ì¸ ë¶„ì„ ë°©ë²•ë¡  ì ìš©
2. ë°ì´í„°ì™€ ì‚¬ì‹¤ì— ê¸°ë°˜í•œ í‰ê°€ ì œê³µ
3. ë‹¤ì–‘í•œ ê´€ì ì—ì„œì˜ ì¢…í•©ì  ë¶„ì„
4. ê°œì„ ì ê³¼ ë°œì „ ë°©í–¥ì— ëŒ€í•œ êµ¬ì²´ì  ì œì•ˆ

ì¶œë ¥: í•œêµ­ì–´ë¡œ ì „ë¬¸ì ì´ê³  ê°ê´€ì ì¸ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•˜ì„¸ìš”.
""",
        
        "summary": f"""
ì‚¬ìš©ì ì…ë ¥: "{user_input}"

ë¶„ì„ëœ ì˜ë„: {intent_analysis.get('intent', 'summary')}
í•œêµ­ì–´ ë¶„ë¥˜: {intent_analysis.get('korean_classification', 'ìš”ì•½/ì •ë¦¬ ìš”ì²­')}

ì‚¬ìš©ìì˜ ìš”ì²­ì´ ëª…í™•í•˜ì§€ ì•Šì§€ë§Œ, ìš”ì•½/ì •ë¦¬ ë§¥ë½ìœ¼ë¡œ ì¶”ë¡ í•˜ì—¬ ê°€ì¥ ì ì ˆí•œ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.

ìš”êµ¬ì‚¬í•­:
1. í•µì‹¬ ë‚´ìš©ì„ ê°„ê²°í•˜ê³  ëª…í™•í•˜ê²Œ ì •ë¦¬
2. ì¤‘ìš”ë„ì— ë”°ë¥¸ ìš°ì„ ìˆœìœ„ ì„¤ì •
3. ì›ë¬¸ì˜ ë§¥ë½ê³¼ ì˜ë„ë¥¼ ìœ ì§€
4. ë…ìê°€ ì‰½ê²Œ ì´í•´í•  ìˆ˜ ìˆëŠ” êµ¬ì¡°ë¡œ êµ¬ì„±

ì¶œë ¥: í•œêµ­ì–´ë¡œ ëª…í™•í•˜ê³  ê°„ê²°í•œ ìš”ì•½ì„ ì œê³µí•˜ì„¸ìš”.
""",
        
        "proposal": f"""
ì‚¬ìš©ì ì…ë ¥: "{user_input}"

ë¶„ì„ëœ ì˜ë„: {intent_analysis.get('intent', 'proposal')}
í•œêµ­ì–´ ë¶„ë¥˜: {intent_analysis.get('korean_classification', 'ì œì•ˆ/ì œì•ˆì„œ ìš”ì²­')}

ì‚¬ìš©ìì˜ ìš”ì²­ì´ ëª…í™•í•˜ì§€ ì•Šì§€ë§Œ, ì œì•ˆ/ì œì•ˆì„œ ë§¥ë½ìœ¼ë¡œ ì¶”ë¡ í•˜ì—¬ ê°€ì¥ ì ì ˆí•œ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.

ìš”êµ¬ì‚¬í•­:
1. ëª…í™•í•œ ëª©í‘œì™€ ê°€ì¹˜ ì œì•ˆ ì œì‹œ
2. ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì  ë°©ì•ˆ ì œì‹œ
3. ì˜ˆìƒ íš¨ê³¼ì™€ ì„±ê³¼ ì§€í‘œ ëª…ì‹œ
4. ë¦¬ìŠ¤í¬ ê´€ë¦¬ ë°©ì•ˆ í¬í•¨

ì¶œë ¥: í•œêµ­ì–´ë¡œ ì„¤ë“ë ¥ ìˆê³  ì‹¤í˜„ ê°€ëŠ¥í•œ ì œì•ˆì„ ì œê³µí•˜ì„¸ìš”.
""",
        
        "general": f"""
ì‚¬ìš©ì ì…ë ¥: "{user_input}"

ë¶„ì„ëœ ì˜ë„: {intent_analysis.get('intent', 'general_inquiry')}
í•œêµ­ì–´ ë¶„ë¥˜: {intent_analysis.get('korean_classification', 'ì¼ë°˜ì ì¸ ìš”ì²­')}

ì‚¬ìš©ìì˜ ìš”ì²­ì´ ëª…í™•í•˜ì§€ ì•Šì§€ë§Œ, ê°€ì¥ ì ì ˆí•œ ë°©ì‹ìœ¼ë¡œ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.

ìš”êµ¬ì‚¬í•­:
1. ì‚¬ìš©ìì˜ ì˜ë„ë¥¼ ìµœëŒ€í•œ ì´í•´í•˜ê³  ì¶”ë¡ 
2. ì‹¤ìš©ì ì´ê³  ë„ì›€ì´ ë˜ëŠ” ì •ë³´ ì œê³µ
3. ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ í†¤ ìœ ì§€
4. ì¶”ê°€ ì§ˆë¬¸ì´ë‚˜ êµ¬ì²´í™”ë¥¼ ìœ„í•œ ì•ˆë‚´ ì œê³µ

ì¶œë ¥: í•œêµ­ì–´ë¡œ ë„ì›€ì´ ë˜ëŠ” ì‘ë‹µì„ ì œê³µí•˜ì„¸ìš”.
"""
    }
    
    return purpose_prompts.get(detected_purpose, purpose_prompts["general"])

def parse_advanced_llm_response(llm_response: str) -> dict:
    """
    ê³ ê¸‰ LLM ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ë°ì´í„°ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    
    Args:
        llm_response (str): LLM ì‘ë‹µ
        
    Returns:
        dict: íŒŒì‹±ëœ ì‘ë‹µ ë°ì´í„°
    """
    try:
        # ê¸°ë³¸ê°’ ì„¤ì •
        parsed = {
            "intent": "general_inquiry",
            "tone": "genuine",
            "tense": "present",
            "audience": "review panel",
            "korean_response": llm_response,
            "confidence": 0.8
        }
        
        # ì˜ë„ ë¶„ë¥˜ ì¶”ì¶œ - ë” ë‹¤ì–‘í•œ íŒ¨í„´ ì§€ì›
        intent_patterns = [
            r"ì˜ë„ ë¶„ë¥˜:\s*(\w+)",
            r"intent:\s*(\w+)",
            r"ë¶„ë¥˜:\s*(\w+)",
            r"ì˜ë„:\s*(\w+)",
            r"ëª©ì :\s*(\w+)",
            r"\*\*Intent Classification:\*\*\s*(\w+)",
            r"\*\*ì˜ë„ ë¶„ë¥˜:\*\*\s*(\w+)",
            r"Intent:\s*(\w+)",
            r"Classification:\s*(\w+)"
        ]
        
        for pattern in intent_patterns:
            match = re.search(pattern, llm_response, re.IGNORECASE)
            if match:
                intent = match.group(1).lower()
                # ì˜ë„ ë§¤í•‘ - ìƒˆë¡œìš´ ì˜ë„ íƒ€ì…ë“¤ ì¶”ê°€
                intent_mapping = {
                    "marketing": "marketing_copy",
                    "content": "content_creation", 
                    "decision": "decision_making",
                    "trend": "trend_verification",
                    "validation": "validation_seeking",
                    "casual": "casual_opinion",
                    "summary": "summary",
                    "business": "business_plan",
                    "proposal": "proposal",
                    "general": "general_inquiry",
                    "investor": "investor_IR_document",
                    "ir": "investor_IR_document",
                    "investment": "investor_IR_document",
                    "ê°ì„±ì ì¸": "marketing_copy",
                    "ë§ˆì¼€íŒ…": "marketing_copy",
                    "ì½˜í…ì¸ ": "content_creation",
                    "ê²°ì •": "decision_making",
                    "íŠ¸ë Œë“œ": "trend_verification",
                    "ê²€ì¦": "validation_seeking",
                    "ìºì£¼ì–¼": "casual_opinion",
                    "ìš”ì•½": "summary",
                    "ì‚¬ì—…": "business_plan",
                    "ì œì•ˆ": "proposal",
                    "íˆ¬ìì": "investor_IR_document",
                    "íˆ¬ì": "investor_IR_document",
                    "ìš”ì²­": "general_inquiry",
                    "suggestion": "suggestion",
                    "content_creation": "content_creation",
                    "marketing_copy": "marketing_copy",
                    "business_plan": "business_plan",
                    "investor_ir_document": "investor_IR_document",
                    "decision_making": "decision_making",
                    "trend_verification": "trend_verification"
                }
                parsed["intent"] = intent_mapping.get(intent, intent)
                break
        
        # í†¤ ì¶”ì¶œ
        tone_patterns = [
            r"í†¤:\s*(\w+)",
            r"tone:\s*(\w+)",
            r"\*\*Tone:\*\*\s*(\w+)",
            r"\*\*í†¤:\*\*\s*(\w+)",
            r"Tone:\s*(\w+)"
        ]
        
        for pattern in tone_patterns:
            match = re.search(pattern, llm_response, re.IGNORECASE)
            if match:
                tone = match.group(1).lower()
                # í†¤ ë§¤í•‘
                tone_mapping = {
                    "genuine": "genuine",
                    "casual": "casual",
                    "formal": "formal",
                    "professional": "professional",
                    "friendly": "friendly",
                    "persuasive": "persuasive",
                    "analytical": "analytical",
                    "supportive": "supportive",
                    "empathetic": "empathetic",
                    "thorough": "thorough",
                    "objective": "objective",
                    "informative": "informative",
                    "ê°ì„±ì ": "genuine",
                    "ì¹œê·¼í•œ": "friendly",
                    "ì „ë¬¸ì ì¸": "professional",
                    "ê²©ì‹ìˆëŠ”": "formal",
                    "ì„¤ë“ì ": "persuasive",
                    "ë¶„ì„ì ": "analytical",
                    "ì§€ì§€ì ": "supportive",
                    "ê³µê°ì ": "empathetic",
                    "ì² ì €í•œ": "thorough",
                    "ê°ê´€ì ": "objective",
                    "ì •ë³´ì ": "informative",
                    "warm": "genuine"
                }
                parsed["tone"] = tone_mapping.get(tone, tone)
                break
        
        # ì‹œì œ ì¶”ì¶œ
        tense_patterns = [
            r"ì‹œì œ:\s*(\w+)",
            r"tense:\s*(\w+)",
            r"\*\*Tense:\*\*\s*(\w+)",
            r"\*\*ì‹œì œ:\*\*\s*(\w+)",
            r"Tense:\s*(\w+)"
        ]
        
        for pattern in tense_patterns:
            match = re.search(pattern, llm_response, re.IGNORECASE)
            if match:
                tense = match.group(1).lower()
                # ì‹œì œ ë§¤í•‘
                tense_mapping = {
                    "present": "present",
                    "past": "past",
                    "future": "future",
                    "í˜„ì¬": "present",
                    "ê³¼ê±°": "past",
                    "ë¯¸ë˜": "future"
                }
                parsed["tense"] = tense_mapping.get(tense, tense)
                break
        
        # ëŒ€ìƒ ì¶”ì¶œ
        audience_patterns = [
            r"ëŒ€ìƒ:\s*(\w+)",
            r"audience:\s*(\w+)",
            r"\*\*Audience:\*\*\s*(\w+)",
            r"\*\*ëŒ€ìƒ:\*\*\s*(\w+)",
            r"Audience:\s*(\w+)"
        ]
        
        for pattern in audience_patterns:
            match = re.search(pattern, llm_response, re.IGNORECASE)
            if match:
                audience = match.group(1).lower()
                # ëŒ€ìƒ ë§¤í•‘
                audience_mapping = {
                    "customer": "customer",
                    "general": "general",
                    "expert": "expert",
                    "review panel": "review panel",
                    "investor": "investor",
                    "personal": "personal",
                    "client": "client",
                    "ê³ ê°": "customer",
                    "ì¼ë°˜": "general",
                    "ì „ë¬¸ê°€": "expert",
                    "íˆ¬ìì": "investor",
                    "ê°œì¸": "personal",
                    "í´ë¼ì´ì–¸íŠ¸": "client"
                }
                parsed["audience"] = audience_mapping.get(audience, audience)
                break
        
        # í•œêµ­ì–´ ì‘ë‹µ ì¶”ì¶œ - ë” ì •êµí•œ íŒ¨í„´ ë§¤ì¹­
        korean_patterns = [
            r"í•œêµ­ì–´ ì‘ë‹µ:\s*(.+)",
            r"response:\s*(.+)",
            r"ì‘ë‹µ:\s*(.+)",
            r"korean response:\s*(.+)",
            r"\*\*Response:\*\*\s*(.+)",
            r"\*\*ì‘ë‹µ:\*\*\s*(.+)",
            r"Response:\s*(.+)"
        ]
        
        korean_response_found = False
        for pattern in korean_patterns:
            match = re.search(pattern, llm_response, re.DOTALL | re.IGNORECASE)
            if match:
                parsed["korean_response"] = match.group(1).strip()
                korean_response_found = True
                break
        
        # íŒ¨í„´ ë§¤ì¹­ì´ ì‹¤íŒ¨í•œ ê²½ìš° ì „ì²´ ì‘ë‹µì—ì„œ í•œêµ­ì–´ ë¶€ë¶„ ì¶”ì¶œ
        if not korean_response_found:
            # í•œêµ­ì–´ê°€ í¬í•¨ëœ ë¶€ë¶„ì„ ì°¾ì•„ì„œ ì‘ë‹µìœ¼ë¡œ ì‚¬ìš©
            korean_sentences = re.findall(r'[ê°€-í£\s\.,!?]+', llm_response)
            if korean_sentences:
                # ê°€ì¥ ê¸´ í•œêµ­ì–´ ë¬¸ì¥ì„ ì„ íƒ
                longest_korean = max(korean_sentences, key=len)
                if len(longest_korean.strip()) > 10:
                    parsed["korean_response"] = longest_korean.strip()
                else:
                    # ì—¬ëŸ¬ í•œêµ­ì–´ ë¬¸ì¥ì„ ì¡°í•©
                    combined_korean = " ".join([s.strip() for s in korean_sentences if len(s.strip()) > 5])
                    if combined_korean:
                        parsed["korean_response"] = combined_korean
                    else:
                        parsed["korean_response"] = llm_response.strip()
            else:
                parsed["korean_response"] = llm_response.strip()
        
        # ì‹ ë¢°ë„ ì¡°ì • - ì˜ë„ ë¶„ë¥˜ê°€ ì„±ê³µí•œ ê²½ìš° ë†’ì€ ì‹ ë¢°ë„
        if parsed["intent"] != "general_inquiry":
            parsed["confidence"] = 0.8
        else:
            parsed["confidence"] = 0.5
        
        return parsed
        
    except Exception as e:
        logger.error(f"LLM ì‘ë‹µ íŒŒì‹± ì¤‘ ì˜¤ë¥˜: {e}")
        return {
            "intent": "general_inquiry",
            "tone": "genuine",
            "tense": "present",
            "audience": "review panel",
            "korean_response": llm_response,
            "confidence": 0.5
        }

def evaluate_reconstructed_confidence(user_input: str, chat_history: list, parsed_response: dict) -> float:
    """
    ê³ ê¸‰ LLM ì¬êµ¬ì„± ê²°ê³¼ì˜ ì‹ ë¢°ë„ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.
    
    Args:
        user_input (str): ì‚¬ìš©ì ì…ë ¥
        chat_history (list): ëŒ€í™” íˆìŠ¤í† ë¦¬
        parsed_response (dict): ê³ ê¸‰ LLM ì¬êµ¬ì„± ê²°ê³¼
        
    Returns:
        float: ì‹ ë¢°ë„ ì ìˆ˜ (0.0 ~ 1.0)
    """
    confidence_score = 0.0
    input_lower = user_input.lower()
    
    # 1. ê³ ê¸‰ LLM ì¬êµ¬ì„± ê²°ê³¼ì˜ ì˜ë„ ë¶„ë¥˜ ì‹ ë¢°ë„ (0.0 ~ 0.3)
    if parsed_response["intent"] != "general_inquiry":
        confidence_score += 0.3
    elif parsed_response["intent"] == "general_inquiry":
        confidence_score += 0.1  # ê¸°ë³¸ ì ìˆ˜
    
    # 2. ì…ë ¥ ê¸¸ì´ ë° ë³µì¡ì„± (0.0 ~ 0.15)
    input_length = len(user_input.strip())
    if input_length > 20:
        confidence_score += 0.15
    elif input_length > 10:
        confidence_score += 0.1
    elif input_length > 5:
        confidence_score += 0.05
    
    # 3. ëª¨í˜¸í•œ íŒ¨í„´ ê°ì§€ (íŒ¨ë„í‹°: -0.0 ~ -0.2) - íŒ¨ë„í‹° ì™„í™”
    ambiguous_patterns = {
        "high_ambiguity": ["ê·¸ëƒ¥", "ì´ê±°", "ìš”ì¦˜", "ëŒ€ì„¸", "ê´œì°®ì•„", "ëŒ€ë°•", "í• ê¹Œ", "í˜•", "bro"],
        "medium_ambiguity": ["just", "this", "trend", "cool", "awesome", "should i", "is this ok"],
        "low_ambiguity": ["ì‚¬ëŒ", "ê°ì„±", "ìê·¹", "ì¨ì¤˜", "people", "emotion", "stimulate", "write"]
    }
    
    ambiguity_penalty = 0.0
    for level, patterns in ambiguous_patterns.items():
        if any(pattern in input_lower for pattern in patterns):
            if level == "high_ambiguity":
                ambiguity_penalty += 0.2  # 0.3ì—ì„œ 0.2ë¡œ ì™„í™”
            elif level == "medium_ambiguity":
                ambiguity_penalty += 0.1  # 0.2ì—ì„œ 0.1ë¡œ ì™„í™”
            elif level == "low_ambiguity":
                ambiguity_penalty += 0.05  # 0.05ì—ì„œ 0.05ë¡œ ìœ ì§€
    
    confidence_score -= ambiguity_penalty
    
    # 4. ë¬¸ì¥ êµ¬ì¡° ë° ì™„ì„±ë„ (0.0 ~ 0.05)
    if user_input.endswith(('.', '!', '?')):
        confidence_score += 0.05
    
    # 5. ë§¥ë½ ì¸ì‹ ê°€ëŠ¥ì„± (0.0 ~ 0.05)
    context_indicators = ["ì´ì „", "ì•ì„œ", "ìœ„ì—ì„œ", "ì•ì˜", "ì´ì „ì—", "before", "previous", "above"]
    if any(indicator in input_lower for indicator in context_indicators):
        confidence_score += 0.05
    
    # 6. ì˜ë„ ë¶„ë¥˜ ì¼ì¹˜ë„ (0.0 ~ 0.1)
    if parsed_response["intent"] != "general_inquiry":
        # êµ¬ì²´ì ì¸ ì˜ë„ ë¶„ë¥˜ê°€ ìˆëŠ” ê²½ìš°
        confidence_score += 0.1
    elif parsed_response["intent"] == "general_inquiry":
        # ì¼ë°˜ì ì¸ ì˜ë„ ë¶„ë¥˜ì¸ ê²½ìš°
        confidence_score += 0.05
    
    # ìµœì¢… ì‹ ë¢°ë„ ì ìˆ˜ ì •ê·œí™” (0.0 ~ 1.0)
    final_confidence = max(0.0, min(confidence_score, 1.0))
    
    # ë¡œê¹…
    logger.info(f"ê³ ê¸‰ ì˜ë„ ì¬êµ¬ì„± ì‹ ë¢°ë„ í‰ê°€ ìƒì„¸:")
    logger.info(f"  - ê³ ê¸‰ LLM ì˜ë„: {parsed_response['intent']}")
    logger.info(f"  - ì…ë ¥ ê¸¸ì´: {input_length}")
    logger.info(f"  - ëª¨í˜¸ì„± íŒ¨ë„í‹°: {ambiguity_penalty}")
    logger.info(f"  - ìµœì¢… ì‹ ë¢°ë„: {final_confidence:.3f}")
    
    return final_confidence

def generate_standardized_prompt_instruction(user_input: str, intent_analysis: dict, chat_history: list = None) -> str:
    """
    ğŸ“‹ [Prompt Instruction Format] ìƒì„±
    
    ì‚¬ìš©ìì˜ ë°œí™”ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í‘œì¤€í™”ëœ í”„ë¡¬í”„íŠ¸ ì§€ì‹œì‚¬í•­ì„ ìƒì„±í•©ë‹ˆë‹¤.
    ì´ëŠ” ìµœì¢… LLM ì‘ë‹µì´ ì•„ë‹Œ, LLMì´ ë”°ë¼ì•¼ í•  ì§€ì‹œì‚¬í•­ì…ë‹ˆë‹¤.
    
    Args:
        user_input (str): ì‚¬ìš©ì ë°œí™”
        intent_analysis (dict): ì˜ë„ ë¶„ì„ ê²°ê³¼
        chat_history (list): ëŒ€í™” íˆìŠ¤í† ë¦¬ (ì„ íƒì‚¬í•­)
        
    Returns:
        str: í‘œì¤€í™”ëœ í”„ë¡¬í”„íŠ¸ ì§€ì‹œì‚¬í•­
    """
    intent = intent_analysis.get("intent", "general_inquiry")
    korean_classification = intent_analysis.get("korean_classification", "ì¼ë°˜ì ì¸ ë¬¸ì˜")
    description = intent_analysis.get("description", "ì¼ë°˜ì ì¸ ì •ë³´ë‚˜ ê°€ì´ë“œ ìš”ì²­")
    tone = intent_analysis.get("tone", "genuine")
    style = intent_analysis.get("style", "informative")
    audience = intent_analysis.get("audience", "general")
    
    # ì˜ë„ë³„ êµ¬ì²´ì ì¸ ëª©ì ê³¼ ì‘ì—… êµ¬ì„±ìš”ì†Œ ì •ì˜
    intent_purposes = {
        "marketing_copy": {
            "purpose": "ê°ì„±ì ì´ê³  ì„¤ë“ë ¥ ìˆëŠ” ë§ˆì¼€íŒ… ì¹´í”¼ë¥¼ ì‘ì„±í•˜ì—¬ ê³ ê°ì˜ ê´€ì‹¬ì„ ëŒê³  í–‰ë™ì„ ìœ ë„",
            "tasks": [
                "ì œí’ˆ/ì„œë¹„ìŠ¤ì˜ í•µì‹¬ ê°€ì¹˜ì™€ í˜œíƒì„ ê°•ì¡°",
                "ê³ ê°ì˜ ê°ì •ê³¼ ìš•êµ¬ì— í˜¸ì†Œí•˜ëŠ” ë©”ì‹œì§€ êµ¬ì„±",
                "ëª…í™•í•œ í–‰ë™ ìœ ë„ ë¬¸êµ¬(CTA) í¬í•¨",
                "ë¸Œëœë“œ í†¤ê³¼ ì¼ì¹˜í•˜ëŠ” ìŠ¤íƒ€ì¼ ì ìš©"
            ]
        },
        "content_creation": {
            "purpose": "ë…ìì—ê²Œ ê°€ì¹˜ë¥¼ ì œê³µí•˜ëŠ” ìœ ìš©í•˜ê³  í¥ë¯¸ë¡œìš´ ì½˜í…ì¸  ì‘ì„±",
            "tasks": [
                "ì£¼ì œì— ëŒ€í•œ ëª…í™•í•˜ê³  êµ¬ì¡°í™”ëœ ì •ë³´ ì œê³µ",
                "ë…ìì˜ ê´€ì‹¬ì„ ëŒ ìˆ˜ ìˆëŠ” í¥ë¯¸ë¡œìš´ ê°ë„ë¡œ ì ‘ê·¼",
                "ì‹¤ìš©ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì¸ì‚¬ì´íŠ¸ í¬í•¨",
                "ë…ìì™€ì˜ ì—°ê²°ê°ì„ í˜•ì„±í•˜ëŠ” ì¹œê·¼í•œ í†¤ ìœ ì§€"
            ]
        },
        "business_plan": {
            "purpose": "íˆ¬ììë‚˜ ì´í•´ê´€ê³„ìì—ê²Œ ì‚¬ì—…ì˜ ê°€ì¹˜ì™€ ì ì¬ë ¥ì„ ëª…í™•í•˜ê²Œ ì „ë‹¬í•˜ëŠ” ì‚¬ì—…ê³„íšì„œ ì‘ì„±",
            "tasks": [
                "ì‚¬ì—… ëª¨ë¸ê³¼ ìˆ˜ìµ êµ¬ì¡°ë¥¼ ëª…í™•í•˜ê²Œ ì„¤ëª…",
                "ì‹œì¥ ë¶„ì„ê³¼ ê²½ìŸ ìš°ìœ„ë¥¼ ì œì‹œ",
                "ì¬ë¬´ ê³„íšê³¼ ì„±ì¥ ì „ëµì„ êµ¬ì²´ì ìœ¼ë¡œ ê¸°ìˆ ",
                "ë¦¬ìŠ¤í¬ ìš”ì¸ê³¼ ëŒ€ì‘ ë°©ì•ˆì„ í¬í•¨"
            ]
        },
        "investor_IR_document": {
            "purpose": "íˆ¬ììì—ê²Œ íšŒì‚¬ì˜ íˆ¬ì ê°€ì¹˜ì™€ ì„±ì¥ ì ì¬ë ¥ì„ ì„¤ë“ë ¥ ìˆê²Œ ì „ë‹¬í•˜ëŠ” IR ë¬¸ì„œ ì‘ì„±",
            "tasks": [
                "íšŒì‚¬ì˜ í•µì‹¬ ê²½ìŸë ¥ê³¼ ì‹œì¥ í¬ì§€ì…˜ì„ ê°•ì¡°",
                "ì¬ë¬´ ì„±ê³¼ì™€ ì„±ì¥ ì§€í‘œë¥¼ ëª…í™•í•˜ê²Œ ì œì‹œ",
                "ë¯¸ë˜ ì „ëµê³¼ íˆ¬ì ê¸°íšŒë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…",
                "íˆ¬ìì ê´€ì ì—ì„œ ì¤‘ìš”í•œ ì •ë³´ë¥¼ ì²´ê³„ì ìœ¼ë¡œ ì •ë¦¬"
            ]
        },
        "decision_making": {
            "purpose": "ì‚¬ìš©ìê°€ í˜„ëª…í•œ ê²°ì •ì„ ë‚´ë¦´ ìˆ˜ ìˆë„ë¡ ê°ê´€ì ì´ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸ ì œê³µ",
            "tasks": [
                "ìƒí™©ì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ì¥ë‹¨ì  ì œì‹œ",
                "ê´€ë ¨ëœ ìœ„í—˜ ìš”ì†Œì™€ ê¸°íšŒ ìš”ì¸ì„ ì‹ë³„",
                "êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ",
                "ì‚¬ìš©ìì˜ ìƒí™©ê³¼ ëª©í‘œì— ë§ëŠ” ë§ì¶¤í˜• ì¡°ì–¸ ì œê³µ"
            ]
        },
        "trend_verification": {
            "purpose": "í˜„ì¬ íŠ¸ë Œë“œë‚˜ ì£¼ì œì˜ ê´€ë ¨ì„±ê³¼ ì¤‘ìš”ì„±ì„ ê°ê´€ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ì •ë³´ ì œê³µ",
            "tasks": [
                "í•´ë‹¹ íŠ¸ë Œë“œì˜ í˜„ì¬ ìƒí™©ê³¼ ë°œì „ ë°©í–¥ ë¶„ì„",
                "ì‹œì¥ì´ë‚˜ ì‚¬íšŒì— ë¯¸ì¹˜ëŠ” ì˜í–¥ í‰ê°€",
                "ê´€ë ¨ëœ ê¸°íšŒì™€ ë„ì „ ê³¼ì œ ì‹ë³„",
                "ì‹¤ìš©ì ì¸ ê´€ì ì—ì„œì˜ ì˜ë¯¸ì™€ ì‹œì‚¬ì  ì œì‹œ"
            ]
        },
        "casual_opinion": {
            "purpose": "ì¹œê·¼í•˜ê³  ì†”ì§í•œ ê´€ì ì—ì„œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ë‚˜ ì£¼ì œì— ëŒ€í•œ ì˜ê²¬ ì œê³µ",
            "tasks": [
                "ê°œì¸ì  ê²½í—˜ê³¼ ê´€ì ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ì†”ì§í•œ ì˜ê²¬ ì œì‹œ",
                "ê¸ì •ì ì´ë©´ì„œë„ í˜„ì‹¤ì ì¸ ê´€ì  ìœ ì§€",
                "ì‚¬ìš©ìì™€ì˜ ê³µê°ëŒ€ í˜•ì„±ì„ ìœ„í•œ ì¹œê·¼í•œ í†¤ ì‚¬ìš©",
                "í•„ìš”ì‹œ ì¶”ê°€ ì •ë³´ë‚˜ ë§¥ë½ì„ ì œê³µ"
            ]
        },
        "general_inquiry": {
            "purpose": "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì´ë‚˜ ìš”ì²­ì— ëŒ€í•´ ìœ ìš©í•˜ê³  ì •í™•í•œ ì •ë³´ ì œê³µ",
            "tasks": [
                "ì§ˆë¬¸ì˜ í•µì‹¬ì„ íŒŒì•…í•˜ì—¬ ëª…í™•í•˜ê³  ê°„ê²°í•œ ë‹µë³€ ì œê³µ",
                "ê´€ë ¨ëœ ë°°ê²½ ì •ë³´ë‚˜ ë§¥ë½ì„ í¬í•¨",
                "ì‹¤ìš©ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸ì´ë‚˜ ì œì•ˆ í¬í•¨",
                "ì‚¬ìš©ìê°€ ì¶”ê°€ ì§ˆë¬¸ì„ í•  ìˆ˜ ìˆë„ë¡ ì¹œê·¼í•œ í†¤ ìœ ì§€"
            ]
        }
    }
    
    # ì˜ë„ì— ë”°ë¥¸ ëª©ì ê³¼ ì‘ì—… êµ¬ì„±ìš”ì†Œ ê°€ì ¸ì˜¤ê¸°
    intent_config = intent_purposes.get(intent, intent_purposes["general_inquiry"])
    purpose = intent_config["purpose"]
    tasks = intent_config["tasks"]
    
    # í†¤ê³¼ ìŠ¤íƒ€ì¼ì„ í•œêµ­ì–´ë¡œ ë³€í™˜
    tone_korean = {
        "persuasive": "ì„¤ë“ì ",
        "informative": "ì •ë³´ ì œê³µì ",
        "genuine": "ì§„ì •ì„± ìˆëŠ”",
        "professional": "ì „ë¬¸ì ",
        "casual": "ì¹œê·¼í•œ",
        "analytical": "ë¶„ì„ì ",
        "supportive": "ì§€ì§€í•˜ëŠ”",
        "empathetic": "ê³µê°í•˜ëŠ”"
    }.get(tone, "ì ì ˆí•œ")
    
    style_korean = {
        "emotional": "ê°ì„±ì ",
        "informative": "ì •ë³´ ì œê³µì ",
        "strategic": "ì „ëµì ",
        "structured": "êµ¬ì¡°í™”ëœ",
        "creative": "ì°½ì˜ì ",
        "practical": "ì‹¤ìš©ì "
    }.get(style, "ì ì ˆí•œ")
    
    audience_korean = {
        "customer": "ê³ ê°",
        "investor": "íˆ¬ìì",
        "client": "í´ë¼ì´ì–¸íŠ¸",
        "general": "ì¼ë°˜",
        "personal": "ê°œì¸"
    }.get(audience, "ì¼ë°˜")
    
    # í‘œì¤€í™”ëœ í”„ë¡¬í”„íŠ¸ ì§€ì‹œì‚¬í•­ ìƒì„±
    instruction = f"""ğŸ“‹ [Prompt Instruction Format]

User utterance: "{user_input}"
Intent: {intent}
Reconstructed Purpose: {purpose}
Instruction:
"""
    
    # ì‘ì—… êµ¬ì„±ìš”ì†Œ ì¶”ê°€
    for task in tasks:
        instruction += f"- {task}\n"
    
    # í†¤, ìŠ¤íƒ€ì¼, ëŒ€ìƒ, ì–¸ì–´ ì§€ì •
    instruction += f"- {tone_korean} í†¤ê³¼ {style_korean} ìŠ¤íƒ€ì¼ë¡œ {audience_korean} ëŒ€ìƒì—ê²Œ ì í•©í•œ ì‘ë‹µ\n"
    instruction += "- Output must be in Korean"
    
    return instruction

def generate_fallback_instruction(user_input: str, intent_analysis: dict) -> str:
    """
    Step 4: Fallback Handling - í…œí”Œë¦¿ ë§¤ì¹­ì´ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ ì§€ì‹œì‚¬í•­ ìƒì„±
    
    ì‚¬ìš©ìì˜ ê°€ëŠ¥í•œ ëª©ì ì„ ì¶”ë¡ í•˜ê³ , ë„ì›€ì´ ë˜ëŠ” ë§¥ë½ ì¸ì‹ ì‘ë‹µì„ í•œêµ­ì–´ë¡œ ìƒì„±í•˜ë©°,
    í•„ìš”í•œ ê²½ìš° ëª…í™•í™”ë¥¼ ìœ„í•œ í›„ì† ì§ˆë¬¸ì„ ì œì•ˆí•©ë‹ˆë‹¤.
    
    Args:
        user_input (str): ì‚¬ìš©ì ì…ë ¥
        intent_analysis (dict): ì˜ë„ ë¶„ì„ ê²°ê³¼
        
    Returns:
        str: ê¸°ë³¸ fallback ì§€ì‹œì‚¬í•­
    """
    return f"""ğŸ“‹ [Prompt Instruction Format]

User utterance: "{user_input}"
Intent: general_inquiry
Reconstructed Purpose: ì‚¬ìš©ìì˜ ìš”ì²­ì„ ë¶„ì„í•˜ì—¬ ê°€ëŠ¥í•œ ëª©ì ì„ ì¶”ë¡ í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ì‘ë‹µ ì œê³µ
Instruction:
- ì‚¬ìš©ìì˜ ë°œí™”ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œë‚˜ ì£¼ì œë¥¼ ì‹ë³„
- ê°€ëŠ¥í•œ ëª©ì ì´ë‚˜ ì˜ë„ë¥¼ ì¶”ë¡ í•˜ì—¬ ë§¥ë½ì— ë§ëŠ” ì‘ë‹µ ìƒì„±
- í•œêµ­ì–´ë¡œ ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” í†¤ìœ¼ë¡œ ì‘ë‹µ
- í•„ìš”ì‹œ ëª…í™•í™”ë¥¼ ìœ„í•œ í›„ì† ì§ˆë¬¸ ì œì•ˆ
- ì‚¬ìš©ìê°€ ì¶”ê°€ ì •ë³´ë¥¼ ì œê³µí•  ìˆ˜ ìˆë„ë¡ ì•ˆë‚´
- ì§„ì •ì„± ìˆëŠ” í†¤ê³¼ ì •ë³´ ì œê³µì  ìŠ¤íƒ€ì¼ë¡œ ì¼ë°˜ ëŒ€ìƒì—ê²Œ ì í•©í•œ ì‘ë‹µ
- Output must be in Korean

ì¶”ê°€ ì§€ì¹¨:
- ì‚¬ìš©ìì˜ ìš”ì²­ì´ ëª¨í˜¸í•œ ê²½ìš°, ê°€ëŠ¥í•œ í•´ì„ë“¤ì„ ì œì‹œ
- êµ¬ì²´ì ì¸ ì˜ˆì‹œë‚˜ ë‹¨ê³„ë³„ ê°€ì´ë“œ ì œê³µ
- ì‚¬ìš©ìì˜ ìƒí™©ì— ë§ëŠ” ì‹¤ìš©ì ì¸ ì¡°ì–¸ í¬í•¨
- í•„ìš”ì‹œ ì¶”ê°€ ì§ˆë¬¸ì„ í†µí•´ ë” ì •í™•í•œ ë„ì›€ì„ ì œê³µí•  ìˆ˜ ìˆë„ë¡ ì•ˆë‚´"""

# í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
def test_prompt_generator():
    """
    í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸°ë¥¼ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
    """
    test_inputs = [
        "ì‚¬ì—…ê³„íšì„œë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”",
        "í˜‘ì—… ì œì•ˆ ì´ë©”ì¼ì„ ë³´ë‚´ì•¼ í•´",
        "ê³ ê° ë¬¸ì˜ì— ë‹µë³€í•´ì•¼ í•´",
        "íšŒì˜ ë‚´ìš©ì„ ìš”ì•½í•´ì£¼ì„¸ìš”",
        "ì„œë¹„ìŠ¤ì— ëŒ€í•œ ë¶ˆë§Œì„ ì œê¸°í•˜ê³  ì‹¶ì–´",
        "ìê¸°ì†Œê°œì„œë¥¼ ì‘ì„±í•´ì•¼ í•´",
        # ìƒˆë¡œìš´ fallback ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ë“¤
        "I have a great idea. What should I do with it?",
        "startup funding needed",
        "ë§ˆì¼€íŒ… ì „ëµì´ í•„ìš”í•´",
        "ê¸°ìˆ  ê°œë°œ ë°©ë²•ì„ ì•Œë ¤ì¤˜",
        "íˆ¬ì ìœ ì¹˜í•˜ê³  ì‹¶ì–´",
        "help me with my business",
        "ì–´ë–»ê²Œ í•´ì•¼ í• ì§€ ëª¨ë¥´ê² ì–´"
    ]
    
    for test_input in test_inputs:
        print(f"\n=== í…ŒìŠ¤íŠ¸: {test_input} ===")
        result = process_user_request(test_input)
        print(f"ì˜ë„: {result['intent']}")
        print(f"ì¡°ê±´: {result['conditions']}")
        print(f"í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(result['prompt'])}")
        print(f"í”„ë¡¬í”„íŠ¸ ë¯¸ë¦¬ë³´ê¸°: {result['prompt'][:150]}...")
        
        # fallback ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸
        if result['intent'] == 'etc':
            print("ğŸ” Fallback ì‹œìŠ¤í…œì´ ì‘ë™í–ˆìŠµë‹ˆë‹¤!")
            fallback_prompt = fallback_prompt_from_topic(test_input)
            print(f"Fallback í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(fallback_prompt)}")
            print(f"Fallback í”„ë¡¬í”„íŠ¸ ë¯¸ë¦¬ë³´ê¸°: {fallback_prompt[:100]}...")

if __name__ == "__main__":
    test_prompt_generator()
