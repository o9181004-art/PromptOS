# ğŸ“ promptos_runner.py

import os
from dotenv import load_dotenv
from llm_api import call_llm_openrouter
from llm_utils import classify_intent_llm
from prompt_generator import extract_conditions, generate_prompt
from prompt_builder import extract_placeholders, prompt_missing_values, fill_template, get_template
from fallback_manager import fallback_manager

load_dotenv()

def run_promptos():
    print("\U0001f9e0 PromptOS MVP - Start\n")

    # 1. ì‚¬ìš©ì ë°œí™” ì…ë ¥
    utterance = input("ğŸ’¬ Enter your instruction: ")

    # 2. Intent ë¶„ë¥˜
    intent = classify_intent_llm(utterance).strip().lower()
    print(f"âœ… Detected Intent: {intent}")

    if intent == "unknown":
        print("âŒ ì•Œ ìˆ˜ ì—†ëŠ” ì‘ì—…ì…ë‹ˆë‹¤. ì˜ˆ: ìš”ì•½ / ìê¸°ì†Œê°œ / ê³ ê° ì‘ëŒ€ ë“±")
        return

    # 3. ì¡°ê±´ ì¶”ì¶œ
    conditions = extract_conditions(utterance)
    print(f"âœ… Extracted Conditions: {conditions}")

    # 4. í…œí”Œë¦¿ ë¶ˆëŸ¬ì˜¤ê¸°
    base_template = get_template(intent)
    if base_template is None:
        print("âš ï¸ í…œí”Œë¦¿ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. LLMì—ê²Œ ì§ì ‘ í”„ë¡¬í”„íŠ¸ ìƒì„±ì„ ìš”ì²­í•©ë‹ˆë‹¤...")
        final_prompt = fallback_manager.generate_prompt_with_llm(utterance, intent)
        print(f"\nğŸŸ¢ LLM ìƒì„± í”„ë¡¬í”„íŠ¸:")
        print(final_prompt)
        
        # 7. LLM í˜¸ì¶œ
        print("\nğŸ¤– Calling LLM...")
        llm_response = call_llm_openrouter(final_prompt)
        print("\nğŸ“¬ GPT Response:\n")
        print(llm_response)
        return

    # 5. ë³´ì™„ê°’ ì…ë ¥ (ì¡°ê±´ ì¤‘ ëˆ„ë½ëœ placeholder)
    placeholders = extract_placeholders(base_template)
    missing_placeholders = [ph for ph in placeholders if ph not in conditions]
    user_values = prompt_missing_values(missing_placeholders, utterance, intent)

    # 6. ìµœì¢… í”„ë¡¬í”„íŠ¸ ìƒì„±
    all_values = {**conditions, **user_values}
    final_prompt = fill_template(base_template, all_values)

    print("\nğŸŸ¢ Final Prompt:")
    print(final_prompt)

    # 7. LLM í˜¸ì¶œ
    print("\nğŸ¤– Calling LLM...")
    llm_response = call_llm_openrouter(final_prompt)
    print("\nğŸ“¬ GPT Response:\n")
    print(llm_response)

if __name__ == "__main__":
    run_promptos()