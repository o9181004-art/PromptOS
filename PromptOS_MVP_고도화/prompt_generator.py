from llm_api.llm_client import call_llm_openrouter

# ğŸ¯ 1. ì˜ë„ ìë™ ë¶„ë¥˜ (LLM ê¸°ë°˜)
def classify_intent(text):
    system_prompt = "You're an AI assistant that classifies user intent."
    user_prompt = f"""
ë‹¤ìŒ ë¬¸ì¥ì˜ ëª©ì ì„ í•˜ë‚˜ ë˜ëŠ” ë³µìˆ˜ë¡œ ë¶„ë¥˜í•´ì¤˜. ê°€ëŠ¥í•œ ì¹´í…Œê³ ë¦¬ëŠ” ë‹¤ìŒê³¼ ê°™ì•„:

['summary', 'self_intro', 'customer_reply', 'business_plan', 'report_write', 'email_reply', 'idea_generation']

ë¬¸ì¥: "{text}"

ì‘ë‹µ í˜•ì‹:
Intent: [ì¹´í…Œê³ ë¦¬1, ì¹´í…Œê³ ë¦¬2, ...]
    """
    response = call_llm_openrouter(system_prompt, user_prompt)
    intent_line = [line for line in response.strip().splitlines() if line.lower().startswith("intent")]
    if intent_line:
        raw = intent_line[0].split(":", 1)[-1].strip()
        return [i.strip() for i in raw.strip('[]').split(',') if i.strip()]
    return []

# ğŸ§  2. ì¡°ê±´ ì¶”ì¶œ (ì‹œì œ, ì–´ì¡°, ë…ì ëŒ€ìƒ)
def extract_conditions(utterance):
    system_prompt = "You are a professional language analyzer that returns structured results."
    user_prompt = f"""
ë‹¤ìŒ ë¬¸ì¥ì˜ ì‹œì œ, ì–´ì¡°, ëŒ€ìƒ ë…ìë¥¼ ë¶„ì„í•´ì¤˜.
ë¬¸ì¥: "{utterance}"

ì¶œë ¥ í˜•ì‹:
Tense: [present/past/future]
Tone: [formal/informal/neutral]
Audience: [general/expert/customer]
    """
    response = call_llm_openrouter(system_prompt, user_prompt)
    lines = response.strip().splitlines()
    conditions = {}
    for line in lines:
        if ":" in line:
            key, value = line.split(":", 1)
            key = key.strip().lower()
            value = value.strip().lower()
            if "tense" in key:
                conditions["tense"] = value
            elif "tone" in key:
                conditions["tone"] = value
            elif "audience" in key:
                conditions["audience"] = value
    return conditions

# ğŸ§± 3. í…œí”Œë¦¿ ë§¤í•‘ í•¨ìˆ˜
def get_template(intent):
    templates = {
        "summary": "Please summarize the following content in a {tone} tone for a {audience} audience.",
        "self_intro": "Introduce yourself focusing on your strengths and experience, using a {tone} tone.",
        "customer_reply": "Respond to the customer's complaint in a {tone} tone, addressing the key concerns.",
        "business_plan": "Write a business plan in a {tone} tone for a {audience} audience.",
        "report_write": "Generate a formal report about the following topic in a {tone} tone.",
        "email_reply": "Compose an email reply with a {tone} tone to a {audience}.",
        "idea_generation": "Generate creative ideas about the following topic in a {tone} tone."
    }
    return templates.get(intent)

# âš™ 4. í…œí”Œë¦¿ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ìƒì„±
def generate_prompt(intent, conditions):
    template = get_template(intent)
    if not template:
        print("âš™ï¸ í…œí”Œë¦¿ ë¯¸ì¡´ì¬ â†’ LLMìœ¼ë¡œ ìë™ í”„ë¡¬í”„íŠ¸ ìƒì„±")
        return generate_prompt_from_llm(intent, conditions)
    try:
        return template.format(**conditions)
    except KeyError:
        return template

# ğŸ§¬ 5. í…œí”Œë¦¿ì´ ì—†ì„ ë•Œ LLM ìƒì„±
def generate_prompt_from_llm(intent, conditions):
    system_prompt = "You're a prompt engineer AI. Generate a well-structured GPT prompt based on the user's intent and style conditions."
    user_prompt = f"""
[Intent]: {intent}
[Conditions]:
- Tense: {conditions.get('tense')}
- Tone: {conditions.get('tone')}
- Audience: {conditions.get('audience')}

Generate a natural, effective GPT prompt that fits these conditions.
Return only the prompt, no explanation.
    """
    return call_llm_openrouter(system_prompt, user_prompt).strip()

# ğŸ” 6. ëˆ„ë½ ì§ˆë¬¸ ìƒì„±
def generate_followup_question(placeholder):
    system_prompt = "You're a helpful assistant that generates clarification questions."
    user_prompt = f"""
ì‚¬ìš©ìê°€ ì‘ì„±í•œ í”„ë¡¬í”„íŠ¸ì— í•„ìš”í•œ ê°’ì´ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤.
ë‹¤ìŒ ì •ë³´ë¥¼ ì–»ê¸° ìœ„í•´ ì–´ë–¤ ì§ˆë¬¸ì„ í• ì§€ ìƒì„±í•´ì£¼ì„¸ìš”.

[í•­ëª©]: {placeholder}

- í•œêµ­ì–´ë¡œ 1ë¬¸ì¥ ì§ˆë¬¸ë§Œ ì¶œë ¥
- ì˜ˆ: 'ë‹¹ì‹ ì˜ ê°•ì ì€ ë¬´ì—‡ì¸ê°€ìš”?'
    """
    return call_llm_openrouter(system_prompt, user_prompt).strip()

# ğŸ“Š 7. í’ˆì§ˆ í‰ê°€
def evaluate_prompt_quality(utterance, prompt, conditions):
    system_prompt = "You are an expert in prompt engineering and prompt evaluation."
    user_prompt = f"""
ì‚¬ìš©ìê°€ ì…ë ¥í•œ ìš”ì²­: "{utterance}"
ìƒì„±ëœ í”„ë¡¬í”„íŠ¸: "{prompt}"

ì¡°ê±´:
- Tense: {conditions.get("tense")}
- Tone: {conditions.get("tone")}
- Audience: {conditions.get("audience")}

ë‹¤ìŒ í•­ëª©ì— ë”°ë¼ í”„ë¡¬í”„íŠ¸ë¥¼ 5ì  ë§Œì ìœ¼ë¡œ í‰ê°€í•´ì£¼ì„¸ìš”:
1. ëª©ì  ì í•©ì„± (Intent Alignment)
2. ëª…í™•ì„± (Clarity)
3. ì™„ê²°ì„± (Completeness)
4. ìŠ¤íƒ€ì¼ ì¼ê´€ì„± (Style Consistency)

í˜•ì‹ ì˜ˆì‹œ:
Intent Alignment: 5  
Clarity: 4  
Completeness: 4  
Style Consistency: 5  

+ ê°„ë‹¨í•œ ê°œì„  ì˜ê²¬ 1ì¤„ í¬í•¨
    """
    return call_llm_openrouter(system_prompt, user_prompt).strip()
