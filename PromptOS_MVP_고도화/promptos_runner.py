import os
from dotenv import load_dotenv
from llm_api.llm_client import call_llm_openrouter
from llm_utils import classify_intent_llm
from prompt_generator import (
    extract_conditions,
    generate_prompt,
    generate_prompt_from_llm,
    evaluate_prompt_quality
)
from prompt_builder import (
    extract_placeholders,
    prompt_missing_values,
    fill_template,
    get_template
)

load_dotenv()

def clean_conditions(conditions):
    """
    ì¡°ê±´ê°’ì—ì„œ '**', ê³µë°± ë“± ë¶ˆí•„ìš”í•œ ê¸°í˜¸ ì œê±°
    """
    cleaned = {}
    for key, value in conditions.items():
        value = value.replace("*", "").replace("-", "").strip()
        cleaned[key] = value
    return cleaned

def run_promptos():
    print("\U0001f9e0 PromptOS MVP - Start\n")

    # 1. ì‚¬ìš©ì ë°œí™” ì…ë ¥
    utterance = input("ğŸ’¬ Enter your instruction: ")

    # 2. Intent ë¶„ë¥˜
    intent = classify_intent_llm(utterance).strip().lower()
    print(f"âœ… Detected Intent: {intent}")

    if intent == "unknown":
        print("âŒ ì•Œ ìˆ˜ ì—†ëŠ” ì‘ì—…ì…ë‹ˆë‹¤. ì˜ˆ: ìš”ì•½ / ìê¸°ì†Œê°œ / ê³ ê° ì‘ëŒ€ ë“±")
        return

    # 3. ì¡°ê±´ ì¶”ì¶œ ë° ì •ì œ
    raw_conditions = extract_conditions(utterance)
    conditions = clean_conditions(raw_conditions)
    print(f"âœ… Extracted Conditions: {conditions}")

    # 4. í…œí”Œë¦¿ ë¶ˆëŸ¬ì˜¤ê¸°
    base_template = get_template(intent)

    if base_template is None:
        print("âš™ï¸ í…œí”Œë¦¿ ë¯¸ì¡´ì¬ â†’ LLMìœ¼ë¡œ ìë™ í”„ë¡¬í”„íŠ¸ ìƒì„±")
        final_prompt = generate_prompt_from_llm(intent, conditions)
    else:
        # 5. ë³´ì™„ê°’ ì…ë ¥
        placeholders = extract_placeholders(base_template)
        missing_placeholders = [ph for ph in placeholders if ph not in conditions]
        user_values = prompt_missing_values(missing_placeholders)

        # 6. ìµœì¢… í”„ë¡¬í”„íŠ¸ ìƒì„±
        all_values = {**conditions, **user_values}
        final_prompt = fill_template(base_template, all_values)

    print("\nğŸŸ¢ Final Prompt:")
    print(final_prompt)

    # âœ… 7. í”„ë¡¬í”„íŠ¸ í’ˆì§ˆ í‰ê°€
    print("\nğŸ“Š Evaluating Prompt Quality...")
    evaluation = evaluate_prompt_quality(utterance, final_prompt, conditions)
    print("\nğŸ“‹ Prompt Evaluation Result:")
    print(evaluation)

    # âœ… 8. LLM í˜¸ì¶œ
    print("\nğŸ¤– Calling LLM...")

    system_prompt = "You are a helpful assistant that generates content based on the given prompt."
    llm_response = call_llm_openrouter(system_prompt, final_prompt)

    print("\nğŸ“¬ GPT Response:\n")
    print(llm_response)

if __name__ == "__main__":
    run_promptos()

